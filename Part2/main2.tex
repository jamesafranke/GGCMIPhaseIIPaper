%% Copernicus Publications Manuscript Preparation Template for LaTeX Submissions
\documentclass[gmd, manuscript]{copernicus} %final manuscript
\definecolor{dark-gray}{gray}{0.55}

\begin{document}
\title{The GGCMI CTWN emulators (version 1.0): global gridded emulators of crop model responses to changes in CO$_2$, Temperature, Nitrogen, and Water}

\Author[1,2]{James}{Franke}
\Author[3]{Christoph}{M\"{u}ller}
\Author[2,4]{Joshua}{Elliott}
\Author[5]{Alex C.}{Ruane}
\Author[3,2,4,5]{Jonas}{J\"{a}germeyr}
\Author[6]{Abigail}{Snyder}
\Author[7]{Marie}{Dury}
\Author[8]{Pete}{Falloon}
\Author[9]{Christian}{Folberth}
\Author[7]{Louis}{Fran{\c{c}}ois}
\Author[10]{Tobias}{Hank}
\Author[11,12]{R.\ Cesar}{Izaurralde}
\Author[7]{Ingrid}{Jacquemin}
\Author[11]{Curtis}{Jones}
%\Author[12]{Marian}{Koch}
\Author[2,13]{Michelle}{Li}
\Author[14,15]{Wenfeng}{Liu}
\Author[16]{Stefan}{Olin}
\Author[5,17]{Meridel}{Phillips}
\Author[18,19]{Thomas A.\ M.}{Pugh}
\Author[11]{Ashwan}{Reddy}
\Author[8]{Karina}{Williams}
%\Author[1,2]{Ziwei}{Wang}
\Author[10]{Florian}{Zabel}
\Author[1,2]{Elisabeth}{Moyer}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\affil[1]{Department of the Geophysical Sciences, University of Chicago, Chicago, IL, USA}
\affil[2]{Center for Robust Decision-making on Climate and Energy Policy (RDCEP), University of Chicago, Chicago, IL, USA}
\affil[3]{Potsdam Institute for Climate Impact Research, Member of the Leibniz Association, Potsdam, Germany}
\affil[4]{Department of Computer Science, University of Chicago, Chicago, IL, USA}
\affil[5]{NASA Goddard Institute for Space Studies, New York, NY, United States}
\affil[6]{Joint Global Change Research Institute, Pacific Northwest National Laboratory, College Park, MD, USA}
\affil[7]{Unit{\'{e}} de Mod{\'{e}}lisation du Climat et des Cycles Biog\'eochimiques, UR SPHERES, Institut d'Astrophysique et de G\'eophysique, University of Li\`ege, Belgium}
\affil[8]{Met Office Hadley Centre, Exeter, United Kingdom}
\affil[9]{Ecosystem Services and Management Program, International Institute for Applied Systems Analysis, Laxenburg, Austria}
\affil[10]{Department of Geography, Ludwig-Maximilians-Universit\"{a}t, Munich, Germany}
\affil[11]{Department of Geographical Sciences, University of Maryland, College Park, MD, USA}
\affil[12]{Texas Agrilife Research and Extension, Texas A\&M University, Temple, TX, USA}
\affil[13]{Department of Statistics, University of Chicago, Chicago, IL, USA}
\affil[14]{EAWAG, Swiss Federal Institute of Aquatic Science and Technology, D\"{u}bendorf, Switzerland}
\affil[15]{Laboratoire des Sciences du Climat et de l'Environnement, LSCE/IPSL, CEA-CNRS-UVSQ, Universit\'{e} Paris-Saclay, F-91191 Gif-sur-Yvette, France.}
\affil[16]{Department of Physical Geography and Ecosystem Science, Lund University, Lund, Sweden}
\affil[17]{Earth Institute Center for Climate Systems Research, Columbia University, New York, NY, USA}
\affil[18]{School of Geography, Earth and Environmental Sciences, University of Birmingham, Birmingham, UK.}
\affil[19]{Birmingham Institute of Forest Research, University of Birmingham, Birmingham, UK.}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\runningtitle{The GGCMI crop model emulators}
\runningauthor{Franke et al.}
\correspondence{James Franke (jfranke@uchicago.edu)}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% These dates will be inserted by Copernicus Publications during the typesetting process.
\received{}
\pubdiscuss{} %% only important for two-stage journals
\revised{}
\accepted{}
\published{}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\firstpage{1}
\maketitle
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}
%\textcolor{red}{
Statistical emulation of process-based crop models provides the opportunity to combine some of the advantageous features of statistical and process-based crop models.  
The Global Gridded Model Intercomparison Project (GGCMI) Phase II consists of a set of simulations run on a suit of process based models with an explicit goal of producing a structured training dataset for crop model emulator development across four dimensions: atmospheric carbon dioxide (CO$_2$) concentrations, temperature, water supply, and nitrogen inputs (CTWN). These training datasets are available for two contrasting assumptions on growing season adaption (A): fixed growing seasons (through adaptation in cultivar choice) and growing seasons shortening in warmer climates (assuming no adaptation in cultivar choice).
In this study we present the construction of a set of crop model emulators of mean-climatological yield for nine process-based crop models and five crops. After presenting the rationale and technical implementation of the emulator construction, we evaluate the emulator performance and discuss the general applicability of these emulators as well as individual cases, where the emulators show unexpected behavior.
%The GGCMI Phase II systematic parameter sweep protocol allows disentangling the climate-driven mean response from year-over-year variations; we show that the two responses have very different relationships to standard climate metrics such as mean growing season temperature. 
The climatological mean yield response can be readily represented with a simple polynomial in almost all locations where crops are currently grown, permitting a tool that captures model responses in a lightweight, computationally tractable form. 
The crop model emulators presented here should therefore facilitate both model comparison and integrated assessment of climate impacts.
%}
\end{abstract}

%\copyrightstatement{TEXT}

\introduction
\label{S:1}
Improving our understanding of the impacts of future climate change on crop yields is critical for global food security in the twenty-first century. 
Projections of future yields under climate change are generally made with one of two approaches: either process-based models, which  simulate the process of photosynthesis and the biology and phenology of individual crops, or statistical models, which use historical weather and yield data to capture relationships between observed crop yields and major drivers.
Process-based crop models provide some advantages, including capturing the direct effects of CO$_2$ fertilization and allowing projections in areas where crops are not currently grown. 
However, they are computationally expensive, and can be difficult or impossible to directly integrate into integrated climate change impacts assessments.
Statistical crop models can only capture crop responses under the range of current conditions, but have several advantages: they implicitly include management and behavioral practices that are difficult to model explicitly, and they are typically simple analytical expressions that are easily implemented by downstream impact modelers. 
Both types of models are routinely used, and comparative studies have concluded that when done carefully, both approaches can provide similar yield estimates \citep[e.g.][]{Lobell2010, Moore2017, Roberts2017, zhao2017,liu2016similar}. 

Statistical emulation allows combining some of the advantageous features of both statistical and process-based models.
Crop model emulators allow representing process-based crop model responses in a computationally-inexpensive form appropriate for economic assessments, and assist in crop model intercomparison and improvement efforts.
The approach involves constructing a ``surrogate model'' of numerical simulations by using their output as training data for a statistical representation \citep[e.g.][]{OHAGAN2006, OHAGAN2010}. 
Emulation is particularly useful in cases where simulations are complex and output data volumes are large, and has been used in a variety of fields, including hydrology \citep[e.g.][]{Razavi2012}, engineering \citep[e.g.][]{STORLIE2009}, environmental sciences \citep[e.g.][]{RATTO2012}, and climate \citep[e.g.][]{Castruccio14, Holden2014}. 
For agricultural impacts studies, emulation of process-based models allows capturing key relationships between input variables in a lightweight, flexible form that is compatible with economic studies. 
Crop model emulation allows producing yield projections under arbitrary emissions scenarios and is an important diagnostic tool for model comparison and model evaluation.

Interest is rising in applying statistical emulation to crop models, and multiple studies have developed crop model emulators in the past decade.
Early studies proposing or describing potential crop yield emulators include \citet{Howden2005, raisen2006, Lobell2010}, and \citet{Ferrise2011}.  %who used a machine learning approach to predict Mediterranean wheat yields. 
Studies developing single-model emulators include  \citet{Holzkamper2012} for the CropSyst model, \citet{RUANE2013a} for the CERES wheat model, and \citet{Oyebamiji15} for the LPJmL model. 
More recently, emulators have begun to be used in the context of multi-model intercomparison, with multiple authors \citep{BLANC2015, BLANC2017, Ostberg2018, Mistry2017}  using them to analyze the five crop models  of the Inter-Sectoral Impact Model Intercomparison Project (ISIMIP). ISIMIP offers a relatively large training set --  control, historical, and several Representative Concentration Pathway (RCP) scenarios using output from up to five climate models \citep{Warszawski3228, Frieler2017} -- and choices of emulation strategy differ.
\citet{BLANC2015} and \citet{BLANC2017} use historical and RPC8.5 scenarios, combine multiple climate model projections for RCP8.5, and regress across soil regions. 
\citet{Ostberg2018} use global mean temperature change (and CO$_2$) as regressors, and then pattern-scales to emulate local yields. 
\citet{Mistry2017} compare emulated and observed historical yields, using local weather data and a historical crop simulation. 
The constraints of the ISIMIP experiment mean that all these efforts do share important common features. 
All emulate annual crop yields along an entire scenario or scenarios, and all future climate scenarios are non-stationary, with important covariates (temperature and precipitation for example) evolving simultaneously. 

An alternative approach to emulation involves construction of a ``parameter sweep'' training set, a collection of multiple stationary scenarios that systematically cover a range of input parameter values.
A parameter sweep offers several important advantages for emulation over an experiment in which climate evolves over time. 
First, it allows separating the effects of different variables that affect yields but that are highly correlated in realistic future scenarios 
like those used in ISIMIP 
(e.g.\ CO$_2$ and temperature). 
Second, it allows making a distinction between year-over-year yield variations and climatological changes, which may involve different responses to the particular climate regressors used \citep[e.g.][]{Ruane2016}. 
For example, if year-over-year yield variations are driven predominantly by variations in the distribution of temperatures throughout the growing period, and long-term climate changes are driven predominantly by shifts in means, then regressing on the mean growing period temperature will produce different yield responses at annual vs.\ climatological timescales.  

Systematic parameter sweeps have begun to be used in crop model evaluation and emulation, with early efforts in 2014 and 2015 \citep{ruane2014, Markowski2015, Pirttioja2015}, and several recent studies in 2018 and 2019 \citep{FRONZEK20182, Snyder2018, RUIZRAMOS2018}. 
These three studies sample multiple perturbations to temperature and precipitation, and two of the three add CO$_2$ as well, for a total of 132, 99 and 220 different combinations, respectively. 
All take advantage of the structured training set to construct emulators (``response surfaces'') of climatological mean yields, omitting year-over-year variations. 
All studies have some limitations, however, for assessing global agricultural impacts. 
None of the 2018 papers offer responses in every grid cell globally, most instead focus on a limited number of sites.
Two involve many crop models but only one crop (wheat) \citep{FRONZEK20182,RUIZRAMOS2018}, while \citet{Snyder2018} analyzes yield responses for four crops from a variety of voluntarily submitted site-specific crop model results, but extrapolates from a network of site yield to latitude zone responses due to data limitations.
%analyzes four crops (maize, wheat, rice, soybean) based on an unevenly distributed sample of sites and crop models \citep{mcdermid2015agmip}.
Snyder et al. analyzes yield responses for four crops from a variety of voluntarily submitted site-specific crop model results, but extrapolates from a network of site yield to latitude zone responses due to data limitations.
% it's based on many crop models if I'm not mistaken. 
% but only in one crop model (GCAM) \citep{calvin2019}.

In this paper we describe a set of globally-gridded crop model emulators developed from the new parameter-sweep dataset of the Global Gridded Crop Model Intercomparison (GGCMI) Phase II effort. 
GGCMI Phase II, a part of the Agricultural Model Intercomparison and Improvement Project (AgMIP) \citep{ROSENZWEIG2013, Rosenzweig2014}, provides the first near-global-coverage systematic parameter sweep of multi-model crop simulations consisting of up to 756 combinations in CO$_2$, temperature, water supply, and applied nitrogen (CTWN). 
%with two counterfactual assumptions on growing season adaptation (A: none vs. regaining growing season length) \citep{franke2019ctwnexperiment,minoli2019adaptation} .
The experiment is specifically designed for construction of crop model emulators, and to allow diagnosing the impacts on crop yields of both individual factors and their joint effects.
In the following, we describe the training dataset (Section \ref{S:2}), the statistical model used for emulation (Section \ref{S:3}), measures of emulator fidelity (Section \ref{S:4}), and examples of preliminary results (Section \ref{S:5}). 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Training dataset}
\label{S:2}
\subsection{The GGCMI Phase II dataset}

\begin{table*}[ht]
    \caption{
    Crop models included in GGCMI Phase II emulators and the number of CTWN-A (Carbon, Temperature, Water, Nitrogen, Adaptation ) simulations performed for each model. 
    The maximum number is 756 for A0 (no adaptation) experiments, and 648 for A1 (maintaining growing length) experiments, since T0 is not simulated under A1. ``N-Dim.'' indicates whether the models are able to represent varying nitrogen levels.
    Each model provides the same set of CTWN simulations across all its modeled crops, but some models omit individual crops. 
    (For example, CARAIB does not simulate spring wheat.)
    Table adapted from \citet{franke2019ctwnexperiment}. 
    For clarity, three simulation models included in Phase II have been removed, those that provided a training set too small to be used in emulation.
    }
    \label{table:models}
    \begin{tabular}{p{6cm} p{1cm} p{1cm} p{1cm} p{1cm} p{1cm} p{1cm} p{1.9cm}}
        \tophline
        \textbf{Model (Key Citations)} & \textbf{Maize} & \textbf{Soybean} & \textbf{Rice} & \textbf{Winter wheat} & \textbf{Spring wheat} & \textbf{N dim.} & \textbf{Sims per crop (A0 / A1)}\\ \middlehline
        \textbf{CARAIB},    \citet{Dury2011, Pirttioja2015}    & X & X & X & X & X & -- & \textbf{252 / 216} \\ \middlehline
        \textbf{EPIC-TAMU}, \citet{Izaurralde06}               & X & X & X & X & X & X & \textbf{756 / 648} \\ \middlehline
        \textbf{JULES},     \citet{Osborne2015, Williams2015, Williams2017} & X & X & X & -- & X & -- & \textbf{252 / 0}\\ \middlehline
        \textbf{GEPIC},     \citet{LIU2007478, FOLBERTH201221} & X & X & X & X & X & X & 430 / 181\\ \middlehline
        \textbf{LPJ-GUESS}, \citet{Lindeskog2013, Olin2015}    & X & -- & -- & X & X & X & \textbf{756 / 648}\\  \middlehline
        \textbf{LPJmL},     \citet{von_Bloh_implementing_2018} & X & X & X & X & X & X & \textbf{756 / 648}\\ \middlehline
        \textbf{pDSSAT},    \citet{Elliott2014b, JONES2003235} & X & X & X & X & X & X & \textbf{756 / 648}\\ \middlehline
        \textbf{PEPIC},     \citet{LIU2016164, LIU2016}        & X & X & X & X & X & X & 149 / 121\\ \middlehline
        \textbf{PROMET},    \citet{Hank2015, MAUSER2015, Zabel2019}       & X & X & X & X & X & X & 261 / 232\\
        \bottomhline
    \end{tabular}
\end{table*}

\begin{table*}[ht]
    \caption{
    GGCMI Phase II input levels for the parameter sweep. 
    Values for temperature and water supply are perturbations from the historical climatology. 
    For water supply, perturbations are fractional changes to historical precipitation, except in the irrigated (W$_{\infty}$) simulations, which are all performed with the maximum beneficial levels of water. 
    Bold font indicates the `baseline' historical level. 
	One model (XX) also provided simulations at the T+5 level. 
    The full protocol samples across all parameter combinations for a total of 756 cases.
    Table repeated from \citet{franke2019ctwnexperiment}.
    }
    \label{table:inputs} 
    \begin{tabular}{lcc} 
        \tophline \vspace{1mm}
        \textbf{Input variable} & \textbf{Tested range} & \textbf{Unit} \\ \middlehline \vspace{1mm}
        [CO$_2$] (C) & \textbf{360}, 510, 660, 810 & ppm\\ \middlehline \vspace{1mm}
        Temperature (T) & -1, \textbf{0}, 1, 2, 3, 4, 6 & $^{\circ}$C\\ \middlehline \vspace{1mm}
        Precipitation (W) & -50, -30, -20, -10, \textbf{0}, & \% \\
        {} & 10, 20, 30, (and W$_{\infty}$) & {} \\ \middlehline \vspace{1mm}
        Applied nitrogen (N) & 10, 60, \textbf{200} & kg ha$^{-1}$ \\ \middlehline \vspace{1mm}
        Adaptation (A) & \textbf{A0: none}, A1: new cultivar to maintain original growing season length & -\\ \bottomhline
    \end{tabular}\\
\end{table*}

The GGCMI Phase II simulations are described in detail in \citet{Franke2019a}, but we summarize briefly here. 
The experiment involves nine different globally gridded crop models, each simulating multiple crops (maize, rice, soybean, and spring and winter wheat) across a systematic parameter sweep of as many as 756 combinations, each driven by a historical climate timeseries with systematic perturbations to CO$_2$, temperature, water supply, and nitrogen application (CTWN). 
Table \ref{table:models} shows the participating models and the number of simulation scenarios that each provides, and Table \ref{table:inputs} shows the specified 4 levels of atmospheric CO$_2$, 7 of temperature, 9 of water supply, and 3 of applied nitrogen. 
See Table \ref{table:inputs} for all values associated with each dimension; we sample across all parameter combinations.

These simulations are repeated for two adaptation scenarios: ``A0'' simulations assume no adaptation in cultivar choice, so that growing seasons shorten in warmer climates, while ``A1'' simulations assume that adaptation in cultivar choice maintains fixed growing seasons. 
The complete protocol for each modeling group involves up to 43,524 years % (4*7*9*3+4*6*9*3)*31, irrigation is one element in W and does not doublicate the full CTWN set. A1 has one element in T less (T=0)
of global simulated output for each crop.
Because the computational demand is high, modeling groups were allowed to submit at various specified levels of participation, with the lowest recommended level of participation consisting of 20\% of the maximum possible simulations; the mean participation level is 65\%. 
Three models (APSIM-UGOE, EPIC-IIASA, and ORCHIDEE-crop) that contributed data to the CTWN-A experiment \citep{Franke2019a} below this recommended threshold (providing samples under 5\% of the full protocol) could not be robustly emulated and so are excluded here.

Each individual crop model simulation is run for 31 years over historic weather for the period of 1980-2010, with added uniform perturbations to any of the CTWN variables.
Historical weather is taken for most models from the AgMERRA \citep{Ruane2015} historical daily climate data product, but the PROMET model uses the ERA-Interim reanalysis \citep{dee2011era} and the JULES model uses a bias-corrected version of ERA-Interim, WFDEI (WATCH-Forcing-Data-ERA-Interim) \citep{weedon2014wfdei} as these groups have specific sub-daily input data requirements. 
Temperature perturbations are applied as additive mean shifts, water supply as fractional multipliers to precipitation (except W$_{\infty}$), and CO$_2$ and nitrogen application as fixed values. 
Models provide global output at 0.5 degree latitude and longitude resolution for each simulation year.

\begin{figure*}[ht]
\centering
   \includegraphics[width=17.5cm]{figures/flowchart.pdf}
   \caption{
   Conceptual framework. 
   }
   \label{fig:yearvclim}
\end{figure*}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Climatological vs. year-to-year response}
\begin{figure*}[ht]
\centering
   \includegraphics[width=15cm]{figures/phase_II_em_figure_1.png}
   \caption{
    Example showing distinction between crop yield responses to year-to-year and climatological mean shifts in climate variables, for  
    maize from the pDSSAT model in a representative high-yield region (nine adjacent grid cells in northern Iowa).
    \textbf{Left}: irrigated maize, all temperature cases (T-1, +0, +1, +2, +3, +4, +6) with other variables held at baseline values, and \textbf{right}: rainfed maize, all precipitation cases (W -50\%, -30\%, -20\%, -10\%, W, +10\%, +20\%, +30\%).
    Open black circles mark climatological mean yields and bold black lines show a 3rd order polynomial fit through them. Colored lines show linear regressions through the 30 annual yields of each parameter case. Colored circles show annual yields for selected cases:
    \textbf{left}: T+0 (blue) and T+6 K (red), and \textbf{right}: W-50\% (brown) and W+50\% (green).
    Maize and soy are more regular in temperature, wheat and rice are not. Precip is irregular in ever case as far as I can tell.
    For temperature, responses to year-over-year fluctuations are very different from those to longer-term climate shifts for some crops: slope of colored and black lines differ. 
    For precipitation, responses to year-over-year responses resemble those to climatological shifts -- colored lines are approximately the tangent of the black line -- but the climatological response is highly nonlinear. 
   }
   \label{fig:yearvclim}
\end{figure*}

\begin{figure*}[ht]
\centering
   \includegraphics[width=7cm]{figures/hist_year_t.png} \hspace{10mm} \includegraphics[width=7cm]{figures/hist_year_pr.png}
   \caption{
   Example showing results of increased crop yield sensitivity to year-over-year climate variations under climate stress. 
   Figure shows distributions of yields from examples of Figure \ref{fig:yearvclim}, of irrigated (\textbf{left}) and rainfed (\textbf{right}) maize in Iowa in scenarios of altered temperature (\textbf{left}) and precipitation (\textbf{right}).
   Under large warming (T+6) or drying (P-50\%), increased sensitivity means that distributions of year-over-year crop yields widen relative to present-day simulations, even though input climate has identical variance in climate drivers.
   }
   \label{fig:yearly}
\end{figure*}

We emulate the climatological mean response, because that is the response of interest in assessments of climate change impacts. 
The year-over-year response can be significantly different from the forced climatological one, so we do not use information from year-to-year variability but instead emulate the aggregated mean yield in each 30-year simulation. 
Emulation then becomes relatively straightforward, since changes in these time-averaged yields are also considerably smoother than those in year-to-year yield response.

In the GGCMI Phase II simulation output dataset, year-over-year responses to weather are indeed quantitatively distinct from  responses to climatological shifts. 
The differences are especially significant for temperature, with yield fluctuations generally stronger in response to short-term temperature fluctuations than in response to changes in climatological means. 
This behavior is illustrated in Figure \ref{fig:yearvclim}, which shows irrigated (left) and rainfed (right) maize in a representative location in Iowa, with black lines and open circles showing the climatological mean responses and colored lines and solid circles those for the 30 individual years in selected scenarios. Yields are three times as sensitive to year-over-year temperature fluctuations as they are to climatological  temperature shifts (1.9 vs.\ 0.6 tons ha$^{-1}$\ K$^{-1}$ in the baseline climate, Figure \ref{fig:yearvclim}, left). Both responses rise slightly at warmer temperatures.
Yield sensitivity to precipitation, on the other hand, is similar for both year-over-year and climatological changes (Figure \ref{fig:yearvclim}, right). Both responses are highly nonlinear and become more severe with increasing dryness. 
\textcolor{red}{XX Should extend to a more general statement about GGCMI behavior.}

While differences in year-over-year and climatological temperature responses can arise for many reasons, including memory in the crop model or lurking covariates,  the most reasonable explanation is that the regressor here, mean growing-season temperature, does not fully describe the conditions that affect crop yields. That is, changes in growing-season temperature \textit{means}  may involve different changes in growing-season temperature \textit{distributions} in the forced and unforced cases \citep[e.g.][]{Ruane2016}. 
This explanation is also consistent with the lack of difference in responses to precipitation perturbations across timescales.  
While changes in temperature distributions can strongly affect crop yields \citep[e.g.][]{Hansen2000, Gadgil2002}, those in precipitation distributions have less effect since crops respond not to rainfall but to soil moisture, which integrates on timescales of weeks or even months \citep[e.g.][]{potter2005effects}. 
%\textcolor{red}{thisis one ref I found but it may not be the best reference and if we drop the claim of "weeks or even months" we can probably also do without a citation here...}
Previous studies have suggested that in all but very arid regions, yields are not sensitive to how precipitation is distributed within a month \citep{Glotter14} although the impact of precipitation distribution within a crop season can be significant \citep{CHALLINOR200499}. 
The difference in responses also suggests that correlation between temperature and precipitation fluctuations does not play a major role. 
\textcolor{red}{XX something about annual P-T correlation in the historical dataset used, the changes seem to be due to just temperature distributions.}

In the GGCMI Phase II experiment, the imposed perturbations involve no changes in underlying distributions. % (reasonable since summertime change are expected to be small \textcolor{red}{cite}).
\textcolor{red}{Will need to say something here in justification - how big are distributional changes in the 30-year series? How big are projected changes?}
However, note that the nonlinearity of yield responses means that the spread in annual yield becomes wider in highly impacted climate states in GGCMI Phase II (Figure \ref{fig:yearly}), even though distributions of climate variables are unchanged.
%\textcolor{red}{\cite{Urban2012} Urban et al here, maybe compare numbers?}
For example, \cite{Urban2012} shows 20\% increase per degree K in variance in maize yields in the US under climate change.
In the GGCMI simulations, higher sensitivity in conditions of extreme climate stress results in greater year-to-year variance in yields for all crops except rice, though we find inc 

\textcolor{red}{The climatological mean response often does not contain a downturn that is present in the year-to-year response for increased precipitation at the extremes... of which models are well know to underestimate \citep{Glotter15,Li2019}.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Emulation}
\label{S:3}
Emulation involves fitting individual regression models from GGCMI Phase II output for each crop and model and 0.5 degree geographic pixel; the regressors are the applied perturbations in CO$_2$, temperature, water, and nitrogen (CTWN). 
We discuss here largely emulations of climatological mean crop yield with no growing season adaptation (A0 scenarios), but note that any output of the crop models can potentially be emulated. 
We provide separate emulations of not only irrigated and rainfed yields but also applied irrigation water (pirrww in mm\ yr$^{-1}$, see \citep{Franke2019a}) in both the A0 and A1 growing season, meaning that each model and crop combination results in six regressions. (See Supplementary Material SXX for more information on additional cases not shown.)

\subsection{Statistical model}
For the statistical model of crop yields as a function of CTWN, we choose a relatively simple parametric model with a 3rd-order polynomial basis function. 
If the climatological mean response is relatively smooth, then a simpler form provides a reasonable fit that allows for some interpretation of resultant parameter weights. 
A relativity simple parametric form also allows fast model emulation at the grid cell level as opposed to the global or large regional level. 
By emulating at the grid cell level, we indirectly include any yield response to geographically distributed factors such as soil type, insolation, and the baseline climate, and preserve the spatial resolution of the parent models.
To facilitate potential parameter-by-parameter comparison across crop models, we hold the functional form constant in space, across all crops, and models. 
That is, the same statistical model is used for all grid cells, models, and rainfed crops. 
Note however that regressions for irrigated crops do not contain W terms and models that do not sample the nitrogen levels omit the N terms.

Both higher-order and interaction terms are expected to be important for representing crop yields. Higher order terms are needed because crop yield responses to weather are well-documented to be nonlinear: e.g.\ \citet{Schlenker2009} for T perturbations and \citet{He2016} for W (precipitation). 
Interaction terms are needed since the yield response is expected to depend on interactions between the major inputs. 
For example, \citet{Lobell2007} and \citet{Tebaldi2008} showed that in real-world yields (with C and N fixed), the joint distribution in T and W is needed to explain observed yield variance.  
Other observation-based studies have shown the importance of the interaction between W and N \citep[e.g.][]{AULAKH2005}, and between N and C \citep{Mitsuru92, Nakamura97}. 

A full third order polynomial with interaction terms for the four regressors (CTWN) has 34 total terms (Equation \ref{eqn:features_original}), too many for robust fitting even with the large GGCMI Phase II dataset. 
We therefore reduce the number of free parameters through a feature selection process (discussed in detail below), eliminating 11 terms that do not play a significant role in predicting crop yields; these are shown in {\color{dark-gray}gray} in Equation \ref{eqn:features_original}. 
The resulting 23-parameter model (Equation \ref{eqn:features_original}) can be well-fitted to crop model response in nearly all regions, with the only exceptions being extremely low-yield regions where crops are not currently grown.

\begin{align}
    \label{eqn:features_original}
    Y\ = \ & K_{1}  \\
    + \ & K_{2} C     + K_{3} T      + K_{4} W      + K_{5} N   \nonumber \\
    + \ & K_{6} C^2   + K_{7} T^2    + K_{8} W^2    + K_{9} N^2 \nonumber \\
    + \ & K_{10} C W  + K_{11} C N   + K_{12} T W   + K_{13} T N \nonumber \\
    + \ & K_{14} W N  +{\color{dark-gray}K_{a} C T} + K_{15} T^3  + K_{16} W^3  + {\color{dark-gray}K_{b} C^3} \nonumber \\
    + \ & {\color{dark-gray}K_{c} N^3} + K_{17} T W N + K_{18} T^2 W + K_{19} W^2 T \nonumber \\
    + \ & K_{20} W^2 N + {\color{dark-gray}K_{d} C W N} + {\color{dark-gray}K_{e} C T N} + K_{21} N^2 C \nonumber \\
    + \ & K_{22} N^2 T + K_{23} N^2 W + {\color{dark-gray}K_{f} T^2 N} + {\color{dark-gray}K_{g} T^2 C}  \nonumber \\
    + \ & {\color{dark-gray}K_{h} W^2 C} + {\color{dark-gray}K_{i} C^2 W} + {\color{dark-gray}K_{j} C^2 T} + {\color{dark-gray}K_{k} C^2 N} \nonumber
\end{align}

We do not focus in this study on comparing different functional forms or non-parametric models.
Some prior studies have used other statistical specifications in crop model emulation: for example, \citet{BLANC2015} and \citet{BLANC2017} use a 39 term fractional polynomial. 
Such a high-dimensional model is difficult to fit, especially for a training set of realistic simulations in which input parameters are highly correlated, and  \citet{BLANC2015} and \citet{BLANC2017}  ``borrow information across space'' by fitting grid points simultaneously across soil region in a panel regression. 
Our simpler functional form can be fit independently at each grid cell while still providing a satisfactory emulation of all GGCMI crop models and crops. 
(See Section \ref{S:4} for evaluation of emulator fidelity.)

\subsection{Feature selection}
To reduce the number of terms in our statistical model, we apply a feature selection cross-validation process in which terms in the polynomial are tested for importance.
In this procedure higher-order and interaction terms are added successively to the regression model one by one, and 
we calculate an aggregate mean absolute error with each increasing terms and eliminate those terms that do not contribute significant reductions in error (top row of Figure \ref{fig:features}). 
Some terms that did not reduce the aggregate error are included if a higher order version of that term provided a decrease in mean squared error: for example, the $T^3$ term cannot be included without also taking the $T^2$ and $T$ terms. 
We select terms by applying the feature selection process to three example models: two that provided the complete set of 672 rainfed simulations (pDSSAT, EPIC-TAMU, and one that provided the smallest training set (120 input combinations, PEPIC). 
Feature importance is not uniform due to spatial heterogeneity across models and crops, so we weight the loss function by current cultivation area \citep{Portmann2010} during this step. 
The resulting choice of terms is then applied for all emulators and all crops. 
Since the goal of the emulator is interpolation within the sample space and not extrapolation, we err on the side of including terms that are useful in at least some cases, because the added predictive ability outweighs the costs to distribution of the residuals or over-fitting.  

\begin{figure*}[ht]
\centering
   \includegraphics[width=12cm]{figures/model_select_maize_rice.png}
   \caption{
   Summary results from polynomial feature selection process.
   The top row illustrates log mean absolute error between emulated yield and simulated values calculated with a three fold cross validation process, where the emulator is trained on two thirds of the data and predicts the remaining third.
   The second row illustrates the adjusted R$^2$ score for the fit at each model specification where additional terms are penalized.
   The third row illustrates the log mean standard parameter error and the forth and fifth rows illustrate the distribution of the residuals.
   The X- axis indicates terms included in the model at each step progressively where T = temperature, T2 = temperature$^{2}$, TW  = temperature * water and so on. 
   The terms that did not reduce the aggregate error (horizontal lines) are not included in the final model. 
   Solid lines indicate Bayesian Ridge regression results, dashed lines indicated standard ordinary least squares and colors indicated three different crop models.
   }
   \label{fig:features}
\end{figure*}

Feature importance is remarkably consistent across models (Figure \ref{fig:features}). 
Even though the models exhibit different absolute levels of error, all three models agree remarkably well on feature importance, that is on  which terms reduce error and which provide no predictive benefit. (Agreement means that line slopes match in Figure \ref{fig:features}.) 
The feature selection process allows us to eliminate 11 terms, leaving a final polynomial in 23 terms.
We necessarily omit the N$^3$ term, which cannot be fitted because we sample only three nitrogen levels, but retain other higher-order N terms. The eliminated terms include many of those in C: the cubic; the CT, CTN, and CWN interaction terms; and all higher order interaction terms in C. 
Finally, we eliminate one 2nd-order interaction term in W and two in T. 
Implications of this choice include that nitrogen interactions are complex and important, and that water interaction effects are more nonlinear than those in temperature. 

\subsection{Model fitting}
To fit the parameters $K$, we use a Bayesian Ridge regularization method \citep{MacKay91}, which reduces volatility in parameter estimates when the sampling is sparse, by weighting parameter estimates towards zero. 
The choice results in a reduction in mean absolute error for some of the high-order interaction terms in the model (top row of Figure \ref{fig:features}) and drastically reduces standard parameter error in the model by stabilizing the estimates.
The estimation method scores relatively lower on adjusted $R^2$ (equation \ref{eqn:rsquare}, where $n$ is the number of samples and $k$ is the number of features) for the simplest parameter specifications, but reaches parity with the OLS at the number of terms included in this study.
The Bayesian Ridge method is necessary over the standard OLS to maintain a consistent functional form across all models and locations (see Table \ref{table:ASE}). 

\begin{equation}
    \label{eqn:rsquare}
    R^{2}_{adj} = 1 - \frac{(n-1) \cdot (1 - R^{2})}{n - k}
\end{equation}

The distribution of the residuals depends on the number of features included in the regression, the method for estimating the parameters, and the target distribution in the training set. 
Including additional higher order terms in the model tends to reduce the skew in the residuals in most cases.
The residuals are only normally distributed (Shapiro–Wilk test \citep{Shapiro1965} pvalue > 0.05) for one of the crop models shown in Figure \ref{fig:features} for any specification tested.
The EPIC-TAMU and pDSSAT crop module emulator residuals are never normally distributed by this metric for any feature specification proposed here. 

We use the implementation of the Bayesian Ridge estimator from the scikit-learn package in Python \citep{scikit-learn}. 
In the GGCMI Phase II experiment, the most problematic fits are those for models that provided a limited number of cases or for low-yield geographic regions where some modeling groups did not run all scenarios. 
The lowest number of simulations emulated across the full parameter space is 120 (for the PEPIC model), since we do not attempt to emulate models that provided less than 50 simulations. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Emulator evaluation}
\label{S:4}
In the following section we present some illustrations of the yield response to drivers and measures of emulator performance. 
In general, model emulation with the parametric method used here is only possible when the crop yield responses are sufficiently smooth and continuous to allow fitting with a relatively simple functional form, but this condition largely holds in the GGCMI Phase II simulations. 
However, losses between the emulator and simulations are great enough to be problematic in certain cases, especially for models with limited sampling or in geographic locations where crops are currently not grown. 
The errors between the simulation and the emulation are generally small compared to the difference across different crop models or across the response to different climate model inputs.

\subsection{Yield response}
\begin{figure*}[ht]
\centering
    \includegraphics[width=16cm]{figures/lpjml_maize.png}
    \caption{
    Illustration of spatial pattern in baseline yield successfully captured by the emulator.
    Simulated (\textbf{a.}) and emulated (\textbf{b.}) yield under historical (1981-2010) conditions for rainfed maize from the LPJmL model.
    Absolute yield differences (\textbf{c.}) are less that 0.5 ton ha$^{-1}$ in almost all (99.8\%) grid cells across the globe.
    Percent difference (from simulated baseline, \textbf{c.}) is below 5\% in most (75\%) grid cells currently cultivated in the real world.
    Approximately 7\% of grid cells have errors over 20\% different from baseline, but only 3\% of grid cells with current cultivation \citep{Portmann2010} have errors over 20\%.
    Notable exceptions include areas with very low baseline yield in the simulations including, for example, the Sahara, the Andes, and northern Quebec. 
    Percent error weighted by cultivation area globally is essentially zero (see also Table \ref{table:ASE}).
    Performance varies by crop and model. 
    See supplemental for more examples.
    }
   \label{fig:map_pattern}
\end{figure*}

\begin{figure*}[ht]
\centering
    \includegraphics[width=16cm]{figures/regression_example_1.png}
    \caption{
    Illustration of spatial variations in yield response successfully captured by the emulator. 
    Figures show rainfed maize in the pDSSAT model in six example locations selected to represent high-cultivation areas around the globe. 
    Legend includes hectares cultivated in each selected grid cell. 
    Each panel shows variation along a single variable, with others held at baseline values. 
    Dots show climatological mean yields and lines the results of the full 4D emulator of Equation \ref{eqn:features_original}. 
    In general the climatological response surface is sufficiently smooth that it can be represented within the sampled variable space by the simple polynomial used in this work. 
    Extrapolation can however produce misleading results. 
    The rainfed maize response in north-central Ontario is shown for the PROMET model as a good example of an area where the emulator fails.
    }
   \label{fig:regression}
\end{figure*}

\begin{figure*}[ht]
\centering
    \includegraphics[width=16cm]{figures/regression_example_2.png}
    \caption{
    Illustration of across-model variations in yield response successfully captured by the emulator. 
    Figures shows simulations and emulations from six models for rainfed maize in the same Iowa grid cell shown in Figure \ref{fig:regression}, with the same plot conventions. 
    Models that do not simulate the nitrogen dimension are omitted for clarity. 
    Note that models are uncalibrated, increasing spread in absolute yields. 
    While most model responses can readily emulated with a simple polynomial, some response surfaces diverge slightly from the polynomial approach (e.g.\ LPJ-GUESS here) and lead to emulation error, though error generally remains small relative to inter-model uncertainty. 
    }
   \label{fig:regression_2}
\end{figure*}

The emulator is able to successfully capture the spatial pattern of yields for a single simulation case and emulation errors are low in regions currently under cultivation (Figure \ref{fig:map_pattern}). 
In this example, nearly all grid cells have errors below 0.5 tons ha$^{-1}$ for the baseline case. 
However, emulation errors as a percentage of baseline yield do reach high values in some areas with no cultivation in the real world.
Many of these regions are not currently viable for agriculture (and therefore have very low simulated baseline yields) and may never become viable even under extreme climate change.  
Some differences in spatial skill exist across models and crops, with maize being the qualitatively easiest to emulate across all models.  
See supplemental Figures SXX-SXX for more crops and models examples. 

Yield responses to the four main drivers considered here (C, T, W, and N) are quite diverse across locations, crops, and models, but in most cases the local climatological mean responses are smooth enough to permit emulation with the functional form used here.
Geographic diversity is high within a single crop and model (Figure \ref{fig:regression}, rainfed maize in pDSSAT); this heterogeneity supports the choice of emulating at the grid cell level. 
Yields evolve smoothly across the space sampled, and the polynomial fit captures the climatological-mean response to perturbations. 
Crop yield responses generally follow similar functional forms across models, though with a spread in magnitude partly due to the lack of calibration. 
Inter-model diversity for a single crop and location is also high (Figure \ref{fig:regression_2}, rainfed maize in northern Iowa, also shown in Figure \ref{fig:regression}). 
Differences in response shape can lead to  differences in the fidelity of emulation, though comparison here is complicated by the different simulation experiment sampling regimes across models. 
Note that models are most similar in their responses to temperature perturbations. 

The emulator fails when the yield response has a discontinuity or is irregular in some regard. 
For example, some simulation models report no yield under current conditions (too cold) and continue to report no yield until a simulation case with a significant amount of warming. 
Under a warming of several degrees, agriculture is now viable in this model and non-zeros yields are returned (Figure \ref{fig:regression}, PROMET in gray). 
Under these conditions, the 3rd order polynomial cannot fit the data, and errors are high. 
Barring simulation model errors, theses locations are almost exclusively confined to areas with little to no cultivation in the real world. 
This is quantified in more detail in the following section.

While the nitrogen dimension is important, it is also the most troublesome to emulate in this work because of its limited sampling compared to other dimensions. 
The GGCMI Phase II protocol specified three nitrogen levels (10, 60 and 200 kg~N y$^{-1}$ ha$^{-1}$), so a third-order fit would be over-determined but a second-order fit can result in potentially unphysical results. 
Steep and nonlinear declines in yield with lower nitrogen levels mean that some regressions imply a peak in yield between the 100 and 200 kg~N y$^{-1}$ ha$^{-1}$ levels. 
While it is possible that over-application of nitrogen at the wrong time in the growing period could lead to reduced yields, these relative strength of this feature is are potentially an artifact of the fit. 
The Bayesian Ridge estimator (shown in Figure \ref{fig:regression}) tends to mitigate the `peak-decline effect' in the nitrogen dimension compared to ordinary least squares. 
In addition, the polynomial fit cannot capture the well-documented saturation effect of nitrogen application \citep[e.g.][]{Torsten77} as accurately as would be possible with a non-parametric model. 

\subsection{Emulator performance metrics}
\begin{figure*}[ht]
\centering
    \includegraphics[width=16cm]{figures/error_grid.png}
    \caption{
    Assessment of emulator performance over currently cultivated areas based on normalized error (Equations \ref{eqn:error}, \ref{eqn:per_yield}). 
    We show performance of all 9 models emulated, over all crops and all sampled T and W inputs (``ir.'' indicates the irrigated W$_{\infty}$ setting), but with CO$_2$ and nitrogen held fixed at baseline values. 
    Large columns are crops and large rows models; squares within are T, W scenario pairs. 
    Colors denote the fraction of currently cultivated hectares (``area frac'') for each crop with normalized area $e$ less that 1 indicating the the error between the emulation and simulation less that one standard deviation of the ensemble simulation spread. 
    Of the 63 scenarios at a single CO$_2$ and N value, we consider only those for which all 9 models submitted data (Figure SX) so the model ensemble standard deviation can be calculated uniformly in each case. 
    JULES did not simulate winter wheat and LPJ-GUESS did not simulate rice and soybean. Emulator performance is generally satisfactory, with some exceptions. 
    Emulator failures (significant areas of poor performance) occur for individual crop-model combinations, with performance generally degrading for colder and wetter scenarios.
    }
   \label{fig:error_360}
\end{figure*}

\begin{figure*}[ht]
\centering
    \includegraphics[width=16cm]{figures/CARAIB_spatial_error.png}
    \caption{
    Illustration of our test of emulator performance, applied to the CARAIB model for the T+4 scenario for rainfed crops. 
    Contour colors indicate the normalized emulator error $e$, where $e > 1$ means that emulator error exceeds the multi-model standard deviation. 
    White areas are those where crops are not simulated by this model. 
    Models differ in their areas omitted, meaning the number of samples used to calculate the multi-model standard deviation is not spatially consistent in all locations. 
    Emulator performance is generally good relative to model spread in areas where crops are currently cultivated (compare to Figure 1) and in temperate zones in general; emulation issues occur primarily in marginal areas with low yield potentials. 
    For CARAIB, emulation of soybean is more problematic, as was also shown in Figure \ref{fig:error_360}.
    }
   \label{fig:error}
\end{figure*}

Our emulators consist of nearly 3 million individual regressions, so presenting concise performance metrics poses a challenge.
Additionally, no general agreed upon criteria exist for defining an acceptable crop model emulator, so we present two different metrics: one operational and one more stringent. 
First, for a multi-model comparison exercise like GGCMI Phase II, one reasonable criterion is what we term the ``normalized error'', which compares the fidelity of an emulator for a given model and scenario to the inter-model uncertainty. 
Second, we show a standard out-of-sample cross-validation aggregate mean error for each model independent of the other members of the ensemble. 

For the first metric, we define the normalized error $e$ for each scenario. The normalized error $e$ is the difference between the emulated fractional change in yield and that actually simulated, normalized by the standard deviation in simulated fractional yield changes across all models for that scenario (Equations \ref{eqn:per_yield} and  \ref{eqn:error}). 

\begin{equation}
    \label{eqn:per_yield}
    F_{\: scn.}= \frac{Y_{scn.}-Y_{baseline}}{Y_{baseline}}
\end{equation}

\begin{equation}
    \label{eqn:error}
    e_{\: scn.} = \frac{F_{em, \: scn.}-F_{sim, \: scn.}}{\sigma_{sim, \: scn.}}
\end{equation}

Here $F_{\: scn.}$ is the fractional change in a model's mean emulated or simulated yield from the defined historical baseline, in a certain setting or scenario (scn.) in C, T, W, and N space; $Y_{scn.}$ and $Y_{baseline}$ are the absolute emulated or simulated mean yields. 
The emulator is fitted across all available simulation outputs for each grid cell, model, and crop, and then the error is calculated across the each of the simulation scenarios provided by all nine models (See Figure SX for number of simulations in each case). 

A normalized error $e<1$ indicates that the emulator is closer to the simulation than 1 standard deviation of the simulations in that scenario.
This metric implies that emulation is generally satisfactory, with almost all model-crop combination emulators have normalized errors less than one over nearly all currently cultivated hectares (Figure \ref{fig:error}, dark colors indicate good performance and light colors poor performance). 
Exceptions include a few individual model-crop combinations, which are difficult to emulate with the polynomial used here including PROMET (as previously mentioned, see also Figure \ref{fig:regression}) for rice and soybean, JULES for soybean and spring wheat. 
Problems with emulating PROMET for rice and soybean may have to do with the parametrization of the phenology for those crops which lengthens the growing season and simulated crop failures in some cases. 
Another reasons why emulation can be problematic in some models has to do with a saturation in yield reduction under temperature increases that cannot be easily captured with the 3rd order fit.
Emulator performance also often degrades in general in geographic locations where crops are not currently cultivated. 
For example, emulator performance may be satisfactory over currently cultivated areas for all crops from a model, but uncultivated regions may show some problematic areas (Figure \ref{fig:error} shows a CARAIB model case, see also Figure SXX-SXX for other models).

The normalized error assessment procedure is relatively forgiving for several reasons. 
First, each emulation is evaluated against the simulations actually used to train the emulator (in-sample validation). 
Had we used a spline interpolation the error would necessarily be zero. 
Second, the performance metric scales emulator fidelity not by the magnitude of yield changes but by the inter-model spread in those changes. 
The normalized error $e$ for a model depends not only on the fidelity of its emulator in reproducing a given simulation but on the particular suite of models considered in the intercomparison exercise. 
Where models differ more widely, the standard for emulators becomes less stringent. 
For example, normalized errors for soybean are somewhat higher across all models not because emulator fidelity is worse but because models agree more closely on yield changes for soybean than for other crops (see Figure SXX), lowering the denominator.
The rationale for this choice of assessment metric is to relate the fidelity of the emulation to an estimate of true uncertainty, which we take as the multi-model spread. 

\begin{figure*}[ht]
  \centering
  \includegraphics[width = 15cm]{figures/emulator_error.png}
  \caption{
    Mean absolute error of emulator representation of a simulation as a percentage of baseline simulated yield for the cross-validation process for rainfed crops. 
    A 4-fold stratified k-fold cross validation scheme is utilized where the model is trained on 75\% of the data and validated on the held-out 25\% (repeated four times). 
    The split does not represent a uniform number of samples in each location or in each model because simulation sampling extent in variable space is heterogeneous. 
    The table shows the mean error (as a percentage of baseline yield) weighted by hectares grown in each grid cell \citep{Portmann2010}.
  }
  \label{fig:all_dims}
\end{figure*}

We also provide a second, more stringent test of emulator performance: a four-fold cross validation (also termed out-of-sample validation). 
In this test the training data is split and the model is trained on 75\% of the data and tested on the held out 25\%.
The mean absolute error is the calculated between the emulated (predicted) and simulated (``ground truth'') values across all cases in the held out 25\% of the simulations. 
The process is then repeated four times to cover all data in the training set. 
Finally, we normalize the mean absolute error in each grid cell by dividing by the simulated yield in that grid cell in the baseline case (T+0, W+0, C=360, N=200) and report a single aggregated mean absolute error values that are weighted by area cultivation area in the real world. 
Geographic locations with very low baseline yields are especially problematic in this metric because minor differences result in high percent errors. 
For this reason we mask all areas with less that 0.1 ton ha$^{-1}$ in the baseline simulation. 

Errors are generally low as a percentage of yield, even for this relatively strict protocol, below 5\% of baseline yield for most crop model combinations (Table \ref{table:ASE}).
The notable exceptions are the JULES model for soybean and spring wheat and the PROMET model for soybean, rice, and the wheats as was seen before in the previous performance metric.
Note that under the conditions of this test, the training set often does not include edge simulations (i.e. those at the highest or lowest value in that dimension).
Predictions in the test phase are therefore extrapolating out to these edge values (e.g.\ predicted a T+6 case that was not included in the training set).
Such an extrapolation during cross validation is not representative based on the intended use of the emulator, which should only be used within the sample space of the overall training set.
Maps showing the spatial patterns of errors can seen in supplemental Figures SXX-SXX. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Emulator results and products}
\label{S:5}
Because the emulator or ``surrogate model'' transforms the discrete simulation samples into a continuous response surface at any geographic scale, it can be used for a variety of applications, including construction of continuous damage functions in a flexible format. 
As an example, we present global damage functions constructed from the 4D emulation, for all four dimensions tested in this study (Figure \ref{fig:all_dims}) with the ensemble median and ensemble spread shown in bold line and ribbon. 
This is helpful in the crop model intercomparison project context for diagnosing model differences. 
In general, across model spread is qualitatively similar across different crops and different dimensions with some notable exceptions. 
Model spread is highest for spring wheat in general and the CO$_2$ response for the wheats and soybean.
On the other side, muted responses include soybean, an efficient atmospheric nitrogen-fixer, is relatively insensitive to nitrogen, rice is not generally grown in water-limited conditions so it shows the lowest response to changes in precipitation, and maize has a muted response to CO$_2$ as a C4 plant.

\begin{figure*}[ht]
  \centering
  \includegraphics[width = 15cm]{figures/em_CTWN_all_crops.png}
  \caption{
  Emulated global damage functions for the five crops included in GGCMI Phase II, from the multi-model mean, for the four dimensions varied: CO$_2$, temperature, water, and nitrogen (collectively ``CTWN''). 
  Solid line shows the multi-model ensemble median and shaded area shows the high and low model projection. 
  All other covariates held constant at baseline values (T+0K, W+0\%, C = 360ppm, and N = 200kg ha-1). 
  Damages are reported as fractional change in production relative to the baseline case over currently cultivated land \citep{Portmann2010}.
  }
  \label{fig:all_dims}
\end{figure*}


\begin{figure*}[ht]
  \centering
  \includegraphics[width = 16.5cm]{figures/LPJMLRCP85comp.png}
  \caption{
  Simulated global production (black) and emulated global production (red) for four crops from the LPJmL model. 
  Points show yearly global production values and lines show spline fit.
  Both simulation and emulation are driven with temperature and precipitation outputs from the HADGEM2-ES model \citep{Jones2011h} for RCP 8.5 with Nitrogen and CO$_2$ held fixed.
  The emulator trained on uniform climatological offset simulation outputs is able to capture the general response of the transient climate run in most cases. 
  Notable exceptions include low simulated production maize for some years in the 1980s, overestimated historical rice, and a persistent low bias for emulated spring wheat.
  }
  \label{fig:all_dims}
\end{figure*}

Note that these functions are presented here in Figure \ref{fig:all_dims} only as examples and do not represent true global projections, because they are developed from simulation data with a uniform temperature shift while increases in global mean temperature should manifest non-uniformly in space and distributions \citep[e.g][]{Sippel2015}. 
The global coverage of the GGCMI Phase II simulations allows impacts modelers to apply arbitrary geographically-varying climate projections, as well as arbitrary aggregation masks, to develop damage functions for any climate scenario and any geopolitical or geographic level bigger than 0.5 degrees in latitude and longitude.

\begin{figure*}[ht]
    \centering
    \includegraphics[width = 16.5cm]{figures/global_em_maize.png}
    \caption{
    Illustration of the effects of factors affecting yields in more realistic climate scenarios. 
    Figure shows emulated yield changes for maize on currently cultivated land under RCP8.5 (relative to 1980-2010 mean) for three representative crop models, with changes to T only (\textbf{a}), to T and W (\textbf{b}), and to T, W, and CO$_2$ (\textbf{c}).
    Circles are emulated decadal yields from 2010-2100 in scenarios from 5 CMIP-5 climate models, i.e.\ 50 total, with x-axis the mean T shift over all grid cells where maize are grown (unweighted by within-cell cultivated area). Rug plot at bottom shows range of final (mean 2090-2100) temperatures across climate models.
    Bold lines are the emulated values over uniform T shifts. 
    Open squares in panel \textbf{a} are GGCMI Phase II simulated values for each T level (with CWN at baseline).  
    Emulations capture simulated behavior well (compare squares to lines), with the exception of PROMET at extreme temperature change. (See also Figure \ref{fig:regression}.)
    Mean yields are very similar whether T changes occur as a uniform temperature shift or in a more realistic spatial pattern (compare lines to circles). 
    \textbf{b:} adding in projected precipitation changes depresses yields slightly for PROMET and increases spread between projections for a given temperature change for the other models. 
    \textbf{c:} adding in CO$_2$ changes produces very different responses across models. CO$_2$ fertilization is small in pDSSAT, moderate in LPJmL, and very large in PROMET. 
    Emulation uncertainty is small compared to the differences across climate and crop models.
    }
    \label{fig:globe_em}
\end{figure*}

The emulator can also be used for investigating the contributions of the different major climate drivers to production outcomes as it can project many different climate scenarios or models quickly.
The emulated crop model yield responses to a high-end climate change scenario (Representative Concentration Pathway (RCP) 8.5) are shown in Figure \ref{fig:globe_em} for 5 climate models from the CMIP-5 archive \citep{Taylor2012} at the decadal scale. See supplemental Figures SXX for the other crops.

The differences between the emulation and the simulations for a uniform T shift are small compared to the differences across different crop models.
PROMET, the quantitatively most difficult model to emulate for maize is shown in Figure \ref{fig:globe_em} to illustrate that emulation error at the global production scale is still small compared to the spread across crop models or the spread across climate projections when all factors are included.
The uniform temperature shift over growing area is not very different from realistic scenarios. 
That is, projected temperature change distribution in space do not matter that much over currently cultivated area, but are likely important to production in high latitude regions which will warm much faster than lower latitudes.

Precipitation changes in RCP8.5 increase damages in a consistent way across most GGCMI crop models.
Precipitation changes introduce some noise because different climate models have different P response for a given temperature change.
Including the direct effects of elevated CO$_2$ introduces the largest intermodel uncertainty with different crop models showing very different responses. 
This difference in model response to CO$_2$ is much larger than differences resulting from different climate model sensitivity to CO$_2$ (T(CO$_2$)).

Finally, the emulator constructed from the GGCMI perturbed mean training set reliably reproduces a realistic RCP scenario indicating that the temperature distribution in a location within the growing season is relatively insignificant when compared to the mean change.
\textcolor{red}{something about growing season length here}
Emulation based on GGCMI climatological mean shifts is useful for realistic scenarios and emulator errors are small compared to climate model differences and tiny compared to crop model differences.

%First, the spatial pattern of temperature change under a realistic climate scenario is relatively insignificant at the global mean production level.

%Second, the spread across climate model response increases considerably with precipitation changes and CO$_2$ effects included, with precipitation changes reducing production and CO$_2$ increasing it.
%The CO$_2$ response is more heterogeneous across crop models that precipitation changes for maize. 
%The globally gridded nature of the emulator allows for easy analysis at almost any spatial scale.
%Note that no direct comparison to the simulations is possible in cases b or c.
%Finally, the emulator can be used to quickly project crop yield responses to climate change under a variety of conditions. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Discussion and conclusions} 
\label{S:6}
We show that the systematic parameter sampling in the GGCMI Phase II experiments allow emulating climatological crop yield responses with a relatively simple reduced-form statistical model. 
The sampling provides information on the influence of multiple interacting factors in a way that realistic climate model simulations cannot, and allows isolating long-term impacts from confounding factors that lead to different year-over-year responses. 
The use of a relatively simple functional form in turn offers the possibility of physical interpretation of parameter values that can assist in model intercomparison and evaluation. 
The yield output for a single GGCMI Phase II model that simulates all scenarios and all five crops is $\sim$12.5 GB; the emulator is $\sim$20 MB, a reduction of nearly three orders of magnitude. 

Several cautions should be noted when using the emulator. While the emulator allows estimating agricultural impacts under arbitrary climate scenarios, extrapolation outside the sample space should be avoided. 
Emulators by design reduce the complexity of process-based simulations and can thus deviate from the raw simulation output. 
This limitation is especially prominent in models with limited sampling or in geographic regions outside the current cultivated area.
Additionally, because the simulation protocol was designed to focus on change in yield under climate perturbations and not on replicating real-world yields, the models are not formally calibrated so cannot be used for impacts projections of absolute yields except in conjunction with historical yield information. 
Finally, because the GGCMI Phase II simulations apply uniform perturbations to historical climate inputs, they do not sample potential changes in climate variability. 
Although such changes are uncertain and remain poorly characterized \citep[e.g.][]{Alexande2006, Kodra2014}, follow-up experiments may wish to consider them. 
Several recent studies have described procedures for generating simulations that combine historical data with model projections of changes in the marginal distributions or temporal dependence of temperature and precipitation (e.g.\ \citet{Leeds2015, poppick2016, Won16} and \citet{Haugen2018}).

The GGCMI Phase II dataset invites a broad range of potential future avenues of analysis, especially because emulation allows statistical distillation of the large dataset (40 billion simulated yields) into a tractable form. 
Potential studies might include a detailed examination of interaction terms between the major input drivers, robust quantification of model sensitivities to input drivers, exploration of yield responses to extremes, and evaluation of geographic shifts in optimal growing regions. 
The dataset also enables studies of emulation itself, including a more systematic evaluation of different statistical and machine learning model specifications.
In general, the development of multi-model ensembles involving systematic parameters sweeps has large promise for better understanding potential future crop responses and for improving process-based crop models.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\codedataavailability{The polynomial emulator parameter matrices for all crop model emulators are available at {doi.org/10.5281/ zenodo.2605374.}}

%\appendix
%\section{}
%\subsection{Data Access}
%\noappendix %% use this to mark the end of the appendix section

\authorcontribution{J.E., C.M, A.R., J.F., and E.M.\ designed the research. C.M., J.J., P.F., C.F., L.F., R.C.I., I.J., C.J., W.L., S.O., M.P., T.P., A.Re., K.W., and F.Z.\ performed the simulations. J.F., J.J., A.S., M.L., and E.M.\ performed the analysis and J.F., C.M., and E.M.\ prepared the manuscript.}

\competinginterests{The authors declare no competing interests.}

\begin{acknowledgements}
We thank Michael Stein and Kevin Schwarzwald, who provided helpful suggestions that contributed to this work. 
This research was performed as part of the Center for Robust Decision-Making on Climate and Energy Policy (RDCEP) at the University of Chicago, and was supported through a variety of sources. 
RDCEP is funded by NSF grant \#SES-1463644 through the Decision Making Under Uncertainty program. 
J.F.\ was supported by the NSF NRT program, grant \#DGE-1735359. x
C.M.\ was supported by the MACMIT project (01LN1317A) funded through the German Federal Ministry of Education and Research (BMBF). 
C.F.\ was supported by the European Research Council Synergy grant \#ERC-2013-SynG-610028 Imbalance-P. 
P.F.\ and K.W.\ were supported  by the Newton Fund through the Met Office Climate Science for Service Partnership Brazil (CSSP Brazil). 
K.W.\ was supported by the IMPREX research project supported by the European Commission under the Horizon 2020 Framework programme, grant \#641811. 
A.S.\ was supported by the Office of Science of the U.S. Department of Energy as part of the Multi-sector Dynamics Research Program Area. 
S.O.\ acknowledges support from the Swedish strong research areas BECC and MERGE together with support from LUCCI (Lund University Centre for studies of Carbon Cycle and Climate Interactions). 
R.C.I.\ acknowledges support from the Texas Agrilife Research and Extension, Texas A \& M University. 
This is paper number 35 of the Birmingham Institute of Forest Research. 
Computing resources were provided by the University of Chicago Research Computing Center (RCC).
This material is based upon work supported by the National Science Foundation Graduate Research Fellowship Program under Grant No. (DGE-1746045). Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the National Science Foundation.
\end{acknowledgements}

\bibliographystyle{copernicus}
\bibliography{bib}

\end{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{table*}[ht]
    \caption{
    Mean absolute error of emulator representation of a simulation as a percentage of baseline simulated yield for the cross-validation process for rainfed crops. 
    A 4-fold stratified k-fold cross validation scheme is utilized where the model is trained on 75\% of the data and validated on the held-out 25\% (repeated four times). 
    The split does not represent a uniform number of samples in each location or in each model because simulation sampling extent in variable space is heterogeneous. 
    The table shows the mean error (as a percentage of baseline yield) weighted by hectares grown in each grid cell \citep{Portmann2010}.
    * Indicates cases where the OLS linear model fails.
    } 
    \label{table:ASE}
    \begin{tabular}{l | c | c | c | c | c} 
        \hline
        \textbf{Model}     & \textbf{Maize (\%)} & \textbf{Soybean (\%)} & \textbf{Rice (\%)} & \textbf{S. Wheat (\%)} & \textbf{W. Wheat (\%)} \\ \hline
        \textbf{CARAIB}    & 1.15  & 4.20  & 2.33  & 0.36  & 0.53   \\ \hline
        \textbf{EPIC-TAMU} & 2.46  & 3.35  & 0.56  & 2.10* & 1.38   \\ \hline
        \textbf{JULES}     & 3.99  & \textbf{20.1} & 2.89  & \textbf{9.90}  & NA     \\ \hline
        \textbf{GEPIC}     & 2.97  & 0.66  & 2.17  & 1.60  & 2.04   \\ \hline
        \textbf{LPJ-GUESS} & 0.57  & NA    & NA    & \textcolor{red}{xxxx}  & 0.18   \\ \hline
        \textbf{LPJmL}     & 2.04  & 1.52  & 1.09  & 0.51  & 0.65   \\ \hline
        \textbf{pDSSAT}    & 2.91  & 1.95  & 2.23  & 0.44  & 1.79   \\ \hline
        \textbf{PROMET}    & 4.41  & \textbf{7.48} & \textbf{6.06}  & \textbf{16.8}  & \textbf{7.07}   \\ \hline
        \textbf{PEPIC}     & 1.30* & 0.72* & 1.16* & 0.63* & 1.65*  \\ \hline
    \end{tabular}
\end{table*}


\Author[1,2]{James}{Franke}
\Author[3]{Christoph}{M\"{u}ller}
\Author[2,4]{Joshua}{Elliott}
\Author[5]{Alex C.}{Ruane}
\Author[6]{Abigail}{Snyder}
\Author[3,2,4,5]{Jonas}{J\"{a}germeyr}
%\Author[7,8]{Juraj}{Balkovic}
\Author[9,10]{Philippe}{Ciais}
\Author[11]{Marie}{Dury}
\Author[12]{Pete}{Falloon}
%\Author[7]{Christian}{Folberth}
\Author[11]{Louis}{Fran{\c{c}}ois}
\Author[13]{Tobias}{Hank}
%\Author[14,23]{Munir}{Hoffmann}
\Author[15,16]{R.\ Cesar}{Izaurralde}
\Author[11]{Ingrid}{Jacquemin}
\Author[15]{Curtis}{Jones}
%\Author[7]{Nikolay}{Khabarov}
\Author[14]{Marian}{Koch}
\Author[2,17]{Michelle}{Li}
\Author[9,18]{Wenfeng}{Liu}
\Author[19]{Stefan}{Olin}
\Author[5,20]{Meridel}{Phillips}
\Author[21,22]{Thomas A.\ M.}{Pugh}
\Author[15]{Ashwan}{Reddy}
%\Author[9,10]{Xuhui}{Wang}
\Author[12]{Karina}{Williams}
\Author[13]{Florian}{Zabel}
\Author[1,2]{Elisabeth}{Moyer}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\affil[1]{Department of the Geophysical Sciences, University of Chicago, Chicago, IL, USA}
\affil[2]{Center for Robust Decision-making on Climate and Energy Policy (RDCEP), University of Chicago, Chicago, IL, USA}
\affil[3]{Potsdam Institute for Climate Impact Research, Member of the Leibniz Association, Potsdam, Germany}
\affil[3]{Department of Computer Science, University of Chicago, Chicago, IL, USA}
\affil[5]{NASA Goddard Institute for Space Studies, New York, NY, United States}
\affil[6]{Joint Global Change Research Institute, Pacific Northwest National Laboratory, College Park, MD, USA}
%\affil[7]{Ecosystem Services and Management Program, International Institute for Applied Systems Analysis, Laxenburg, Austria}
%\affil[8]{Department of Soil Science, Faculty of Natural Sciences, Comenius University in Bratislava, Bratislava, Slovak Republic}
\affil[9]{Laboratoire des Sciences du Climat et de l'Environnement, CEA-CNRS-UVSQ, 91191 Gif-sur-Yvette, France}
\affil[10]{Sino-French Institute of Earth System Sciences, College of Urban and Env. Sciences, Peking University, Beijing, China}
\affil[11]{Unit{\'{e}} de Mod{\'{e}}lisation du Climat et des Cycles Biog\'eochimiques, UR SPHERES, Institut d'Astrophysique et de G\'eophysique, University of Li\`ege, Belgium}
\affil[12]{Met Office Hadley Centre, Exeter, United Kingdom}
\affil[13]{Department of Geography, Ludwig-Maximilians-Universit\"{a}t, Munich, Germany}
\affil[14]{Georg-August-University G\"{o}ttingen, Tropical Plant Production and Agricultural Systems Modeling, G\"{o}ttingen, Germany}
\affil[15]{Department of Geographical Sciences, University of Maryland, College Park, MD, USA}
\affil[16]{Texas Agrilife Research and Extension, Texas A\&M University, Temple, TX, USA}
\affil[17]{Department of Statistics, University of Chicago, Chicago, IL, USA}
\affil[18]{EAWAG, Swiss Federal Institute of Aquatic Science and Technology, D\"{u}bendorf, Switzerland}
\affil[19]{Department of Physical Geography and Ecosystem Science, Lund University, Lund, Sweden}
\affil[20]{Earth Institute Center for Climate Systems Research, Columbia University, New York, NY, USA}
\affil[21]{School of Geography, Earth and Environmental Sciences, University of Birmingham, Birmingham, UK.}
\affil[22]{Birmingham Institute of Forest Research, University of Birmingham, Birmingham, UK.}
\affil[23]{Leibniz Centre for Agricultural Landscape Research (ZALF), D-15374 Müncheberg, Germany}

%\textcolor{red}{The experiment involves twelve different globally gridded crop models, each simulating multiple crops (maize, rice, soybean and spring and winter wheat) over as many as 1400 simulations, each driven by historical climate inputs with systematically perturbations to CO$_2$, temperature, precipitation, and nitrogen application (CTWN).
%The resulting dataset allows }
%is the most comprehensive crop model emulation effort to date, significantly expanding the scope of previous parameter-sweep crop model emulation work by incorporating 

 %Furthermore, the year-over-year response is nonlinear with baseline climate: while the climatological response is nearly the same in T+0 to T+6 scenarios, evolving only from XX-XX tons ha$^{-1}$/K, the year-over-year response rises by over a quarter, from 1.9 to 2.5 tons ha$^{-1}$/K. 
%The same general principal applies to a lesser degree the precipitation dimension however in this case it is more manifestly an artifact of sampling range in the historical period (Figure \ref{fig:yearvclim}, right).

%While differences in year-over-year and climatological temperature responses can arise for many reasons, including memory in the crop model and lurking covariates, the most reasonable explanation is that the regressors here, mean growing-season temperature, does not fully describe the conditions that affect crop yields. That is, changes in growing-season temperature \textit{means}  may involve different changes in growing-season temperature \textit{distributions}  in the forced and unforced cases \citep[e.g.][]{Ruane2016}. 
%In the GGCMI Phase II experiment, the imposed perturbations involve no changes in underlying distributions (reasonable since summertime change are expected to be small \cite{XX}), but year-over-year variations are \textit{XX}. Note that year-over-year distributions of yields do become wider in highly impacted climate states in GGCMI Phase II (Figure \ref{fig:yearly}), but only because yield responses to both temperature and precipitation perturbations are nonlinear.
%It is expected that precipitation perturbations would produce more similar responses on year-over-year and climatological scales, because changes in precipitation distributions affect yields less than do those in temperature. Crops respond not to precipitation but to soil moisture, which integrates on timescales of weeks or even months \cite{XX}. Previous studies have suggested that in all but very arid regions, yields are not sensitive to how precipitation is distributed within a month \citep{Glotter14}.

%Ensemble spread dependence can be readily seen when comparing assessments of emulator performance in simulations at baseline CO$_2$ (Figure \ref{fig:error_360}) with those at higher CO$_2$ levels (Figure SXX) because models disagree on the magnitude of CO$_2$ fertilization. 
%We therefore do not provide a formal parameter uncertainty analysis, but note that the GGCMI Phase II dataset is well-suited to statistical exploration of emulation approaches and quantification of emulator fidelity. 
%More rigorous emulator assessments that could be preformed in future work include: testing other statistical specifications including non-parametric models and calculating standard error on emulator parameters.

%construct this test in some case we are extrapolating, which is not the intended use... 
%cross validation process often does not include ``edge'' simulations in the training set (i.e. those at the highest or lowest value in that dimension) on one or more folds of the training set split.
%The ``edge'' cases are then predicted during the prediction phase of cross validation.
%Such an extrapolation during cross validation is not representative based on the intended use of the emulator, which should only be used within the sample space of the overall training set.
%(the process is then repeated four times to cover all data in the training set). 
