%% Copernicus Publications Manuscript Preparation Template for LaTeX Submissions
\documentclass[gmd, manuscript]{copernicus} %final manuscript
\definecolor{dark-gray}{gray}{0.55}

\begin{document}
\title{The GGCMI phase II emulators: global gridded crop model responses to changes in CO$_2$, temperature, water, and nitrogen (version 1.0)}

\Author[1,2]{James}{Franke}
\Author[3]{Christoph}{M\"{u}ller}
\Author[2,4]{Joshua}{Elliott}
\Author[5]{Alex C.}{Ruane}
\Author[3,2,4,5]{Jonas}{J\"{a}germeyr}
\Author[6]{Abigail}{Snyder}
\Author[7]{Marie}{Dury}
\Author[8]{Pete}{Falloon}
\Author[9]{Christian}{Folberth}
\Author[7]{Louis}{Fran{\c{c}}ois}
\Author[10]{Tobias}{Hank}
\Author[11,12]{R.\ Cesar}{Izaurralde}
\Author[7]{Ingrid}{Jacquemin}
\Author[11]{Curtis}{Jones}
\Author[2,13]{Michelle}{Li}
\Author[14,15]{Wenfeng}{Liu}
\Author[16]{Stefan}{Olin}
\Author[5,17]{Meridel}{Phillips}
\Author[18,19]{Thomas A.\ M.}{Pugh}
\Author[11]{Ashwan}{Reddy}
\Author[8]{Karina}{Williams}
\Author[1,2]{Ziwei}{Wang}
\Author[10]{Florian}{Zabel}
\Author[1,2]{Elisabeth}{Moyer}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\affil[1]{Department of the Geophysical Sciences, University of Chicago, Chicago, IL, USA}
\affil[2]{Center for Robust Decision-making on Climate and Energy Policy (RDCEP), University of Chicago, Chicago, IL, USA}
\affil[3]{Potsdam Institute for Climate Impact Research, Member of the Leibniz Association, Potsdam, Germany}
\affil[4]{Department of Computer Science, University of Chicago, Chicago, IL, USA}
\affil[5]{NASA Goddard Institute for Space Studies, New York, NY, United States}
\affil[6]{Joint Global Change Research Institute, Pacific Northwest National Laboratory, College Park, MD, USA}
\affil[7]{Unit{\'{e}} de Mod{\'{e}}lisation du Climat et des Cycles Biog\'eochimiques, UR SPHERES, Institut d'Astrophysique et de G\'eophysique, University of Li\`ege, Belgium}
\affil[8]{Met Office Hadley Centre, Exeter, United Kingdom}
\affil[9]{Ecosystem Services and Management Program, International Institute for Applied Systems Analysis, Laxenburg, Austria}
\affil[10]{Department of Geography, Ludwig-Maximilians-Universit\"{a}t, Munich, Germany}
\affil[11]{Department of Geographical Sciences, University of Maryland, College Park, MD, USA}
\affil[12]{Texas Agrilife Research and Extension, Texas A\&M University, Temple, TX, USA}
\affil[13]{Department of Statistics, University of Chicago, Chicago, IL, USA}
\affil[14]{EAWAG, Swiss Federal Institute of Aquatic Science and Technology, D\"{u}bendorf, Switzerland}
\affil[15]{Laboratoire des Sciences du Climat et de l'Environnement, LSCE/IPSL, CEA-CNRS-UVSQ, Universit\'{e} Paris-Saclay, F-91191 Gif-sur-Yvette, France.}
\affil[16]{Department of Physical Geography and Ecosystem Science, Lund University, Lund, Sweden}
\affil[17]{Earth Institute Center for Climate Systems Research, Columbia University, New York, NY, USA}
\affil[18]{School of Geography, Earth and Environmental Sciences, University of Birmingham, Birmingham, UK.}
\affil[19]{Birmingham Institute of Forest Research, University of Birmingham, Birmingham, UK.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\runningtitle{The GGCMI crop model emulators}
\runningauthor{Franke et al.}
\correspondence{James Franke (jfranke@uchicago.edu)}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% These dates will be inserted by Copernicus Publications during the typesetting process.
\received{}
\pubdiscuss{} %% only important for two-stage journals
\revised{}
\accepted{}
\published{}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\firstpage{1}
\maketitle
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}
Statistical emulation allows combining advantageous features of statistical and process-based crop models for understanding the effects of future climate changes on crop yields.  We describe here the development of emulators for nine process-based crop models and five crops using output from the Global Gridded Model Intercomparison Project (GGCMI) Phase II. The GGCMI Phase II experiment %involves simulations by a suite of process-based models and 
	is designed with the explicit goal of producing a structured training dataset for emulator development that samples across four dimensions relevant to crop yields: atmospheric carbon dioxide (CO$_2$) concentrations, temperature, water supply, and nitrogen inputs (CTWN). 
Simulations are run under two different adaptation assumptions: that growing seasons shorten in warmer climates, and that cultivar choice allows growing seasons to remain fixed.  The dataset allows emulating the climatological mean yield response without relying on interannual variations; we show that these are quantitatively different.
Climatological mean yield responses can be readily captured with a simple polynomial in nearly all locations, with errors significant only in some marginal lands where crops are not currently grown. 
%rationale and technical implementation of the emulator construction, we evaluate the emulator performance and discuss the general applicability of these emulators as well as individual cases, where the emulators show unexpected behavior.
%The GGCMI Phase II systematic parameter sweep protocol allows disentangling the climate-driven mean response from year-over-year variations; we show that the two responses have very different relationships to standard climate metrics such as mean growing season temperature. 
In general, emulation errors are negligible relative to differences across crop models or even across climate model scenarios. We demonstrate that the resulting GGCMI emulators can reproduce yields under realistic future climate simulations, even though the GGCMI Phase II dataset is constructed with uniform CTWN offsets, suggesting that effects of changes in temperature and precipitation distributions are small relative to those of changing means. The resulting emulators therefore capture relevant crop model responses in a lightweight, computationally tractable form, providing a tool that can facilitate model comparison, diagnosis of interacting factors affecting yields, and integrated assessment of climate impacts.
%of mean-climatological yields
\end{abstract}

%\copyrightstatement{TEXT}

\introduction
\label{S:1}
Improving our understanding of the impacts of future climate change on crop yields is critical for global food security in the twenty-first century. 
Projections of future yields under climate change are generally made with one of two approaches: either process-based models, which  simulate the process of photosynthesis and the biology and phenology of individual crops, or statistical models, which use historical weather and yield data to capture relationships between observed crop yields and major drivers.
Process-based crop models provide some advantages, including capturing the direct effects of CO$_2$ fertilization and allowing projections in areas where crops are not currently grown. 
However, they are computationally expensive, and can be difficult or impossible to directly integrate into integrated climate change impacts assessments.
Statistical crop models can only capture crop responses under the range of current conditions, but have several advantages: they implicitly include management and behavioral practices that are difficult to model explicitly, and they are typically simple analytical expressions that are easily implemented by downstream impact modelers. 
Both types of models are routinely used, and comparative studies have concluded that when done carefully, both approaches can provide similar yield estimates \citep[e.g.][]{Lobell2010, Moore2017, Roberts2017, zhao2017,liu2016similar}. 

Statistical emulation allows combining some of the advantageous features of both statistical and process-based models.
The approach involves constructing a ``surrogate model'' of numerical simulations by using their output as training data for a statistical representation \citep[e.g.][]{OHAGAN2006, OHAGAN2010}. 
Emulation is particularly useful in cases where simulations are complex and output data volumes are large, and has been used in a variety of fields, including hydrology \citep[e.g.][]{Razavi2012}, engineering \citep[e.g.][]{STORLIE2009}, environmental sciences \citep[e.g.][]{RATTO2012}, and climate \citep[e.g.][]{Castruccio14, Holden2014}. 
For agricultural impacts studies, emulation of process-based models allows capturing key relationships between input variables in a lightweight, flexible form that is compatible with economic studies. 
The resultant statistical model can produce yield projections under arbitrary emissions scenarios and is an important diagnostic tool for model comparison and model evaluation.

Interest is rising in applying statistical emulation to crop models, and multiple studies have developed crop model emulators in the past decade.
Early studies proposing or describing potential crop yield emulators include \citet{Howden2005, raisen2006, Lobell2010}, and \citet{Ferrise2011}.
Studies developing single-model emulators include  \citet{Holzkamper2012} for the CropSyst model, \citet{RUANE2013a} for the CERES wheat model, and \citet{Oyebamiji15} for the LPJmL model. 
More recently, emulators have begun to be used in the context of multi-model intercomparison, with multiple authors \citep{BLANC2015, BLANC2017, Ostberg2018, Mistry2017}  using them to analyze the five crop models  of the Inter-Sectoral Impact Model Intercomparison Project (ISIMIP). ISIMIP offers a relatively large training set --  control, historical, and several Representative Concentration Pathway (RCP) scenarios using output from up to five climate models \citep{Warszawski3228, Frieler2017} -- and choices of emulation strategy differ.
\citet{BLANC2015} and \citet{BLANC2017} use historical and RPC8.5 scenarios, combine multiple climate model projections for RCP8.5, and regress across soil regions. 
\citet{Ostberg2018} use global mean temperature change (and CO$_2$) as regressors, and then pattern-scales to emulate local yields. 
\citet{Mistry2017} compare emulated and observed historical yields, using local weather data and a historical crop simulation. 
The constraints of the ISIMIP experiment mean that all these efforts do share important common features. 
All emulate annual crop yields along an entire scenario or scenarios, and all future climate scenarios are non-stationary, with important covariates (temperature and precipitation for example) evolving simultaneously. 

An alternative approach to emulation involves construction of a ``parameter sweep'' training set, a collection of multiple stationary scenarios that systematically cover a range of input parameter values.
A parameter sweep offers several important advantages for emulation over an experiment in which climate evolves over time. 
First, it allows separating the effects of different variables that affect yields but that are highly correlated in realistic future scenarios like those used in ISIMIP (e.g.\ CO$_2$ and temperature). 
Second, it allows making a distinction between year-over-year yield variations and climatological changes, which may involve different responses to the particular climate regressors used \citep[e.g.][]{Ruane2016}. 
For example, if year-over-year yield variations are driven predominantly by variations in the distribution of temperatures throughout the growing period, and long-term climate changes are driven predominantly by additive mean shifts, then regressing on the mean growing period temperature will produce different yield responses at annual vs.\ climatological timescales.  

Systematic parameter sweeps have begun to be used in crop model evaluation and emulation, with early efforts in 2014 and 2015 \citep{ruane2014, Markowski2015, Pirttioja2015}, and several recent studies in 2018 and 2019 \citep{FRONZEK20182, RUIZRAMOS2018,Snyder2018}. 
These three studies sample multiple perturbations to temperature and precipitation, and two of the three add CO$_2$ as well, for a total of 132, 99 and 220 different combinations, respectively. 
All take advantage of the structured training set to construct emulators (``response surfaces'') of climatological mean yields, omitting year-over-year variations. 
All the 2018--2019 papers have some limitations, however, for assessing global agricultural impacts, including that
none evaluate responses in every grid cell globally.
Two involve many crop models but only one crop (wheat) \citep{FRONZEK20182,RUIZRAMOS2018} and cover only 1--4 individual sites. 
\citet{Snyder2018} analyzes five crops over $\sim$1000 sites with individual site-specific crop models, and extrapolates in space to estimate mean latitudinal responses.

In this paper we describe a set of globally-gridded crop model emulators developed from the new parameter-sweep dataset of the Global Gridded Crop Model Intercomparison (GGCMI) Phase II effort. 
GGCMI Phase II, a part of the Agricultural Model Intercomparison and Improvement Project (AgMIP) \citep{ROSENZWEIG2013, Rosenzweig2014}, provides the first near-global-coverage systematic parameter sweep of multi-model crop simulations consisting of up to 756 combinations in CO$_2$, temperature, water supply, applied nitrogen, and two different assumptions on growing season adaptation (``A0'': none and ``A1'': retaining growing season length) \citep[CTWN-A, ][]{franke2019ctwnexperiment,minoli2019adaptation}.
The experiment is designed to allow diagnosing the impacts on crop yields of both individual factors and their joint effects, and to allow construction of crop model emulators.
In the following, we describe the training dataset (Section \ref{S:2}), the statistical model used for emulation (Section \ref{S:3}), measures of emulator fidelity (Section \ref{S:4}), and examples of preliminary results (Section \ref{S:5}). 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Training dataset}
\label{S:2}
\subsection{The GGCMI Phase II dataset}

\begin{table*}[ht]
    \caption{
    Crop models included in GGCMI Phase II emulators and the number of CTWN-A (Carbon, Temperature, Water, Nitrogen, Adaptation ) simulations performed for each model. 
    The maximum number is 756 for A0 (no adaptation) experiments, and 648 for A1 (maintaining growing length) experiments, since T0 is not simulated under A1. 
    ``N-Dim.'' indicates whether the models are able to represent varying nitrogen levels.
    Each model provides the same set of CTWN simulations across all its modeled crops, but some models omit individual crops.
    Table adapted from \citet{franke2019ctwnexperiment}. 
    For clarity, three simulation models included in Phase II are not shown here, those that provided a training set too small to be used in emulation.
    }
    \label{table:models}
    \begin{tabular}{p{6cm} p{1cm} p{1cm} p{1cm} p{1cm} p{1cm} p{1cm} p{1.9cm}}
        \tophline
        \textbf{Model (Key Citations)} & \textbf{Maize} & \textbf{Soybean} & \textbf{Rice} & \textbf{Winter wheat} & \textbf{Spring wheat} & \textbf{N dim.} & \textbf{Sims per crop (A0 / A1)}\\ \middlehline
        \textbf{CARAIB},    \citet{Dury2011, Pirttioja2015}    & X & X & X & X & X & -- & \textbf{252 / 216} \\ \middlehline
        \textbf{EPIC-TAMU}, \citet{Izaurralde06}               & X & X & X & X & X & X & \textbf{756 / 648} \\ \middlehline
        \textbf{JULES},     \citet{Osborne2015, Williams2015, Williams2017} & X & X & X & -- & X & -- & \textbf{252 / 0}\\ \middlehline
        \textbf{GEPIC},     \citet{LIU2007478, FOLBERTH201221} & X & X & X & X & X & X & 430 / 181\\ \middlehline
        \textbf{LPJ-GUESS}, \citet{Lindeskog2013, Olin2015}    & X & -- & -- & X & X & X & \textbf{756 / 648}\\  \middlehline
        \textbf{LPJmL},     \citet{von_Bloh_implementing_2018} & X & X & X & X & X & X & \textbf{756 / 648}\\ \middlehline
        \textbf{pDSSAT},    \citet{Elliott2014b, JONES2003235} & X & X & X & X & X & X & \textbf{756 / 648}\\ \middlehline
        \textbf{PEPIC},     \citet{LIU2016164, LIU2016}        & X & X & X & X & X & X & 149 / 121\\ \middlehline
        \textbf{PROMET},    \citet{Hank2015, MAUSER2015, Zabel2019}  & X & X & X & X & X & -- & 261 / 232\\
        \bottomhline
    \end{tabular}
\end{table*}

\begin{table*}[ht]
    \caption{
    GGCMI Phase II input levels for the parameter sweep. 
    Values for temperature and water supply are perturbations from the historical climatology. 
    For water supply, perturbations are fractional changes to historical precipitation, except in the irrigated (W$_{\infty}$) simulations, which are all performed with the maximum beneficial levels of water. 
    Bold font indicates the `baseline' historical level. 
    The full protocol samples across all parameter combinations for a total of 756 cases.
    Table repeated from \citet{franke2019ctwnexperiment}.
    }
    \label{table:inputs} 
    \begin{tabular}{lcc} 
        \tophline \vspace{1mm}
        \textbf{Input variable} & \textbf{Tested range} & \textbf{Unit} \\ \middlehline \vspace{1mm}
        [CO$_2$] (C) & \textbf{360}, 510, 660, 810 & ppm\\ \middlehline \vspace{1mm}
        Temperature (T) & -1, \textbf{0}, 1, 2, 3, 4, 6 & $^{\circ}$C\\ \middlehline \vspace{1mm}
        Precipitation (W) & -50, -30, -20, -10, \textbf{0}, & \% \\
        {} & 10, 20, 30, (and W$_{\infty}$) & {} \\ \middlehline \vspace{1mm}
        Applied nitrogen (N) & 10, 60, \textbf{200} & kg ha$^{-1}$ \\ \middlehline \vspace{1mm}
        Adaptation (A) & \textbf{A0: none}, A1: new cultivar to maintain original growing season length & -\\ \bottomhline
    \end{tabular}\\
\end{table*}

The GGCMI Phase II simulations are described in detail in \citet{franke2019ctwnexperiment}, but we summarize briefly here. 
The experiment involves nine different globally gridded crop models, each simulating multiple crops (maize, rice, soybean, and spring and winter wheat) across a systematic parameter sweep of as many as 756 combinations, each driven by a historical climate timeseries with systematic perturbations to CO$_2$, temperature, water supply, and nitrogen application (CTWN). 
The simulation protocol involves 4 levels of atmospheric CO$_2$, 7 of temperature, 9 of water supply, and 3 of applied nitrogen, and simulations are repeated for two adaptation scenarios: ``A0'' simulations assume no adaptation in cultivar choice, so that growing seasons shorten in warmer climates, and ``A1'' simulations assume that adaptation in cultivar choice maintains fixed growing seasons.
The complete protocol for each modeling group involves up to 43,524 years of global simulated output for each crop. 
Because the computational demand is high, modeling groups were allowed to submit at various specified levels of participation, with the lowest recommended level of participation consisting of 20\% of the maximum possible simulations. The mean participation level is 65\%, but three models (APSIM-UGOE, EPIC-IIASA, and ORCHIDEE-crop) contributed data below the recommended threshold ($<$ 5\% of the full protocol) and are excluded here since they could not be robustly emulated. 
Table \ref{table:models} shows the participating models and the number of simulation scenarios that each provides, and Supplemental Figure S1 shows model sampling density. Table \ref{table:inputs} shows the specified input values; we sample across all parameter combinations. 

Each individual crop model simulation is run for 31 years over historic weather for the period of 1981-2010, with added uniform perturbations to any of the CTWN variables.
Historical weather is taken for most models from the AgMERRA \citep{Ruane2015} historical daily climate data product, but the PROMET model uses the ERA-Interim reanalysis \citep{dee2011era} and the JULES model uses a bias-corrected version of ERA-Interim, WFDEI \citep[WATCH-Forcing-Data-ERA-Interim,][]{weedon2014wfdei} as these groups have specific sub-daily input data requirements. 
Temperature perturbations are applied as additive mean shifts, water supply as fractional multipliers to precipitation (except in the irrigated W$_{\infty}$ case), and CO$_2$ and nitrogen application levels are specified as fixed values. 
Models provide near-global output at 0.5 degree latitude and longitude resolution for each simulation year, including areas not currently cultivated. 
In analyses where we distinguish yields over currently cultivated land, we use the masks of \citet{Portmann2010}. 
(See Supplemental Figures S2--3 for maps of cultivated area.)

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Climatological vs. year-to-year response}

We emulate the climatological mean response, because that is the response of interest in assessments of climate change impacts. 
The year-over-year response can be significantly different from the forced climatological one, so we do not use information from year-to-year variability but instead emulate the aggregated mean yield in each 30-year simulation. 
Emulation then becomes relatively straightforward, since changes in time-averaged yields are also considerably smoother than those in year-to-year yield response.

In the GGCMI Phase II simulation output dataset, year-over-year responses to weather are often quantitatively distinct from responses to climatological shifts, with the discrepancy especially strong in wheat and rice. 
The difference in behavior is illustrated in Figure \ref{fig:yearvclim}, which shows irrigated and rainfed maize and wheat in representative locations; open circles and black lines show the climatological mean response, and solid circles and colored lines the responses for the 30 individual years in individual scenarios.
When discrepancies are large, year-over-year responses are generally stronger than climatological ones, but exact responses differ by crop and region and even by model within GGCMI Phase II. 

\begin{figure*}[ht]
\centering
   \includegraphics[width=15cm]{figures/phase_II_em_figure_1.png}
   \caption{
   Example showing distinction between crop yield responses to year-to-year and climatological mean shifts in climate variables, showing representative high-yield regions for maize in pDSSAT (northern Iowa, top row) and winter wheat in EPIC-TAMU (France, bottom row).
   Left column (\textbf{a \& c}) shows irrigated crops, all temperature cases
   with other variables held at baseline values, and right column (\textbf{b \& d}) shows rainfed crops, all precipitation cases.
   Figure shows A0 output, in which growing seasons shift under future climate, so local growing-season temperature changes can differ from prescribed uniform offsets: for example, a 5 K applied uniform warming results in a growing season temperature warmer by $\sim$7 K for maize in Iowa (top right), but by less than 5 K for wheat in France (bottom right). 
   Open black circles mark climatological mean yields and bold black lines show a 3rd order polynomial fit through them. 
   Colored lines show linear regressions (by orthogonal distance regression) through the 30 annual yields of each parameter case.
   Colored circles show annual yields for selected cases.
   Differences in slopes of colored and black lines mean that responses to year-over-year fluctuations differ from those to longer-term climate shifts. Differences are generally stronger for wheat (bottom) than maize (top).
   Note that for rain-fed crops, slope differences in this representation could also result from correlated precipitation and temperature fluctuations in the baseline timeseries, but P-T correlations do not contribute to the effects shown here. 
   Such correlations would complicate emulations based on year-over-year yields but would not necessarily bias them.
   %See Supplemental Figures SX-SX for other crops, models, and locations.
   }
   \label{fig:yearvclim}
\end{figure*}

While differences in responses at different timescales can arise for many reasons, including memory in the crop model or lurking covariates, the most likely explanation here is that the regressors used, mean growing-season temperature or precipitation, do not fully describe the conditions that affect crop yields. 
The mean growing-season value is only a proxy for the distribution of daily climatic conditions that crops are sensitive to, and present-day variations between years can be very different from future forced changes. 
That is, present-day variations in growing-season \textit{means} from year to year may be associated with changes in growing-season \textit{distributions} that are unrelated to any changes in future warmer climates: a warm year at present may be quite different from a warm year in the future \citep[e.g.][]{Ruane2016}. % XX not sure this is the right citation for this...
Changes in temperature distributions have been shown to strongly affect crop yields \citep[e.g.][]{Hansen2000, Gadgil2002}, though precipitation effects should be smaller since crops respond not to rainfall but to soil moisture, which integrates over weeks or even months \citep[e.g.][]{potter2005effects, Glotter14, CHALLINOR200499}. 

A second factor of importance is that any nonlinearity in crop responses will itself lead to a distinction between climatological and year-over-year fits, even if distributional differences are negligible. 
Given the interannual variations in the climate timeseries, the mean annual yield response to a perturbation is not the same as the response of the climatological mean yield. 
The effect of nonlinearity may be particularly relevant for precipitation, since model crop yields drop steeply and nonlinearly with increasing dryness. 
(Crop yields should drop under excess precipitation as well, but process-based models do not capture losses in saturated conditions well \citep{Glotter15,Li2019}.) 

In the GGCMI Phase II experiment, the imposed perturbations involve no changes in underlying distributions.
The choice is reasonable, since climate models do not agree on distributional changes.
Most models do project small mean increases in growing-season temperature variability in cultivated areas, and can produce substantial local changes, but models disagree on spatial patterns (Supplemental Figure S4).
For example, in the high-end (Representative Concentration Pathway (RCP) 8.5 \citep{riahi2011rcp}) climate projections to the year 2100 in the Coupled Model Intercomparison Project Phase 5 (CMIP-5) archive, growing season temperature variability over currently cultivated rice areas increases by 31\% in HadCM3L but decreases by 12\% in CESM1-0-1. 
We therefore explicitly test the assumption that distributional changes are not consequential for climatological mean yields: in Section \ref{S:4.3}, we confirm that an emulator trained on the GGCMI Phase II dataset can successfully reproduce yield changes under a full climate model projection.

\begin{figure*}[ht]
\centering
   \includegraphics[width=7cm]{figures/hist_year_t.png} \hspace{10mm} \includegraphics[width=7cm]{figures/hist_year_pr.png}
   \caption{
   Example showing results of increased crop yield sensitivity to year-over-year climate variations under climate stress. 
   Yield distributions are from examples of Figure \ref{fig:yearvclim}, top row, of maize in Iowa, (\textbf{left}) for irrigated maize in scenarios of altered temperature and (\textbf{right}) for rainfed maize in scenarios of altered precipitation.
   Because yield sensitivities rise under strong warming or drying, distributions of year-over-year crop yields widen in T+6  and P-50\% scenarios relative to present-day simulations, even though all input climate timeseries have identical variance for temperature. Note: precipitation changes have different variance since the perturbations are fractional.  
    }
   \label{fig:yearly}
\end{figure*}

Note that even though distributions of climate variables are unchanged in the GGCMI Phase II simulations, the spread in annual yields still becomes wider in highly impacted climate states, because of the nonlinearity of yield responses (Figure \ref{fig:yearly}). 
In the GGCMI Phase II dataset, all crops except rice show  greater year-to-year yield variance in conditions of extreme climate stress.
(Rice is typically irrigated and experiences no water stress.) 
Increased variance has been noted in previous studies. 
For example, \citet{Urban2012} used statistical models trained on present-day yields to find a projected future increase in yield variance of U.S.\ maize of 20\% per degree K temperature rise. While the authors do not diagnose a specific cause of that increase, they discuss multiple potential mechanisms, including nonlinearity in responses. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Emulation}
\label{S:3}
Emulation involves fitting individual regression models from GGCMI Phase II output for each crop and model and 0.5 degree geographic pixel; the regressors are the applied perturbations in CO$_2$, temperature, water, and nitrogen (CTWN). 
We discuss here largely emulations of climatological mean crop yields with no growing season adaptation (A0 scenarios), but note that any output of the crop models can potentially be emulated. 
We provide separate emulations of irrigated and rainfed yields and applied irrigation water (pirrww in mm\ yr$^{-1}$) in both A0 and A1 scenarios, meaning that each model and crop combination results in six sets of regressions. See Supplemental Material Sections 4, 5, and 7 for these additional emulation cases.

\subsection{Statistical model}
For the statistical model of crop yields as a function of CTWN, we choose a relatively simple parametric model with a 3rd-order polynomial basis function. 
If the climatological mean response is relatively smooth, then a simpler form provides a reasonable fit that allows for some interpretation of resultant parameter weights. 
A relativity simple parametric form also allows fast model emulation at the grid cell level, rather than requiring spatial aggregation. 
Emulating at the grid cell level preserves the spatial resolution of the parent models, and means that emulators indirectly includes any yield response to geographically distributed factors such as soil type, insolation, and the baseline climate.

The 3rd-order polynomial CTWN model contains 34 terms (Equation \ref{eqn:features_original}), since the N$^3$ term is omitted, as it cannot be fitted in a training set sampling only three nitrogen levels. 
To facilitate comparing emulators parameter by parameter, we hold this functional form across locations, crops, and models, other than several necessary distinctions: regressions for irrigated crops do not contain W terms, and regressions for models that do not sample the nitrogen levels omit the N terms. 

\vspace{-0.2in}
\begin{align}
    \hspace{10mm}  \label{eqn:features_original}
    Y\ = \ & K_{1}  \\
    + \ & K_{2} C    + K_{3} T     + K_{4} W   + K_{5} N  + K_{6} C^2 \nonumber \\
    + \ & K_{7} T^2  + K_{8} W^2   + K_{9} N^2 + K_{10} C W           \nonumber \\
    + \ & K_{11} C N + K_{12} T W  + K_{13} T N + K_{14} W N          \nonumber \\
    + \ & K_{15} C T + K_{16} T^3  + K_{17} W^3  + K_{18} C^3 + {\color{dark-gray}K_{*} N^3} \nonumber \\
    + \ & K_{19} T W N + K_{20} T^2 W + K_{21} W^2 + K_{22} W^2 N     \nonumber \\
    + \ & K_{23} C W N + K_{24} C T N + K_{25} C T W + K_{26} N^2 C   \nonumber \\
    + \ & K_{27} N^2 T + K_{28} N^2 W + K_{29} T^2 N + K_{30} T^2 C   \nonumber \\
    + \ & K_{31} W^2 C + K_{32} C^2 W + K_{33} C^2 T + K_{34} C^2 N   \nonumber
\end{align}

Results shown throughout the paper use this full specification, but we also investigate (in Section \ref{sec:features} below) whether some terms can be dropped without significant reduction in emulator fidelity.
In general, both higher-order and interaction terms are expected to be important for representing crop yields. Higher order terms are needed because crop yield responses to weather are well-documented to be nonlinear: e.g.\ \citet{Schlenker2009} for T perturbations and \citet{He2016} for W (precipitation). 
Interaction terms are needed since the yield response is expected to depend on interactions between the major inputs. 
For example, \citet{Lobell2007} and \citet{Tebaldi2008} showed that in real-world yields (with C and N fixed), the joint distribution in T and W is needed to explain observed yield variance.  
Other observation-based studies have shown the importance of the interaction between W and N \citep[e.g.][]{AULAKH2005}, and between N and C \citep{Mitsuru92, Nakamura97}.

We do not focus in this study on comparing other functional forms or non-parametric models.
Some prior studies have used other statistical specifications in crop model emulation: for example, \citet{BLANC2015} and \citet{BLANC2017} use a 39 term fractional polynomial and ``borrow information across space'' by fitting grid points simultaneously across soil region in a panel regression. 
The GGCMI Phase II dataset allows fitting our simple 3rd order polynomial form independently at each grid cell while still providing a satisfactory emulation for all models and crops. 
(See Section \ref{S:4} for evaluation of the fidelity of emulators constructed with Equation \ref{eqn:features_original}.)

\subsection{Feature importance and reduced statistical model}
\label{sec:features}

Because a simpler statistical model may improve the interpretability of its parameter weights, we also develop a reduced version that is satisfactory for most models and crops (Equation \ref{eqn:features_reduced}).
To identify terms that can be omitted, we apply a feature selection cross-validation process in which terms in the polynomial are tested for importance. Higher-order and interaction terms are successively added to the regression model, and in each case we calculate an aggregate mean absolute error (weighted by by currently cultivated area) and eliminate those terms that do not contribute significantly to reducing error. The procedure is illustrated in Figure \ref{fig:features}. We develop our reduced statistical model by considering yields over currently cultivated land in three models: two that provided the complete set of 672 rainfed simulations, i.e. without the W$_{\infty}$ simulations,  (pDSSAT, EPIC-TAMU), and one that provided the smallest training set (121 input combinations, PEPIC).
Although models exhibit different absolute levels of error, all three agree remarkably well on feature importance, i.e.\ on which terms reduce error and which provide no predictive benefit. (Agreement means that line slopes match in Figure \ref{fig:features}.) 
 
\begin{figure*}[ht]
\centering
   \includegraphics[width=16.3cm]{figures/model_select_maize_rice.png}
    \caption{
    Illustration of results from the polynomial feature selection process for three different crop models (colors), for all grid cells with more than 1000 ha cultivated for maize (\textbf{left}) and rice (\textbf{right}). 
    Solid lines are Bayesian Ridge regression results and dashed lines those for standard OLS. Rows show four metrics of fit quality and x axes the terms successively tested in the statistical model, sequentially added to the model in order from left to right.
    Terms that do not reduce the aggregate error are marked in {\color{dark-gray} gray} and are not included in the final model. 
    \textbf{a \& b:} log mean absolute error between emulated yield and simulated values calculated with a three fold cross validation process, where the emulator is trained on two thirds of the data and predicts the remaining third.
    \textbf{c \& d:} log mean standard parameter error. The Bayesian Ridge method strongly reduces parameter error and results in more stable estimates. 
    \textbf{e \& f:} adjusted R$^2$ score for the fit at each model specification. 
    \textbf{g \& h:} distribution of the residuals. Skewness is low at the high model specifications tested in all model cases other than EPIC-TAMU maize.
    }
   \label{fig:features}
\end{figure*}

Results of the feature selection process suggest that 11 terms can be omitted with negligible impact on emulator fidelity, producing the 23-term statistical model of Equation \ref{eqn:features_reduced}.
\vspace{-0.2in}
\begin{align}
        \hspace{10mm} \label{eqn:features_reduced}
    Y\ = \ & K_{1}  \\
    + \ & K_{2} C      + K_{3} T       + K_{4} W    + K_{5} N  + K_{6} C^2 \nonumber \\
    + \ & K_{7} T^2    + K_{8} W^2     + K_{9} N^2  + K_{10} C W \nonumber \\
    + \ & K_{11} C N   + K_{12} T W    + K_{13} T N + K_{14} W N \nonumber \\
    + \ & {\color{dark-gray}K_{a} C T} + K_{15} T^3 + K_{16} W^3  + {\color{dark-gray}K_{b} C^3} + {\color{dark-gray}K_{c} N^3}\nonumber \\
    + \ & K_{17} T W N + K_{18} T^2 W  + K_{19} W^2 + K_{20} W^2 N  \nonumber \\
    + \ & {\color{dark-gray}K_{d} C W N} + {\color{dark-gray}K_{e} C T N} + {\color{dark-gray}K_{f} C T W} + K_{21} N^2 C \nonumber \\
    + \ & K_{22} N^2 T + K_{23} N^2 W    + {\color{dark-gray}K_{g} T^2 N} + {\color{dark-gray}K_{h} T^2 C}                 \nonumber \\
    + \ & {\color{dark-gray}K_{i} W^2 C} + {\color{dark-gray}K_{j} C^2 W} + {\color{dark-gray}K_{k} C^2 T} + {\color{dark-gray}K_{l} C^2 N} \nonumber
\end{align}

\noindent The eliminated terms include many of those in C: the cubic; the CT, CTN, CTW, and CWN interaction terms; and all higher order interaction terms in C. 
Finally, we eliminate one 2nd-order interaction term in W and two in T. 
Implications of this choice include that nitrogen interactions are complex and important, and that water interaction effects are more nonlinear than those in temperature.  
Note that some terms that did not reduce the aggregate error must still be included if a higher order version of that term provides benefit: for example, including the $T^3$ term requires also retaining $T^2$ and $T$ terms. 
The reduced-form emulator is acceptable across currently cultivated land for all model and crop combinations other than JULES soy and spring wheat and PROMET soy and rice.
These cases involve yield responses that benefit strongly from inclusion of higher order carbon interaction terms. 
Additional terms in the statistical model also help emulation in some geographic locations outside of currently cultivated regions, where yield responses are often non-standard. 
(See Supplemental Material Section 8 for evaluation of the fidelity of emulators constructed with Equation \ref{eqn:features_reduced} and for more details on JULES and PROMET.)

\subsection{Model fitting}
To fit the parameters $K$, we use a Bayesian Ridge regularization method \citep{MacKay91} rather than standard ordinary least squares (OLS). 
The Bayesian Ridge method reduces volatility in parameter estimates when the sampling is sparse, by weighting parameter estimates towards zero, allowing the use of a consistent functional form across all models and locations. 
The choice slightly reduces mean absolute error for some of the high-order interaction terms in the model (Figure \ref{fig:features}, top row) but drastically reduces standard parameter error in the model by stabilizing the estimates (Figure \ref{fig:features}, third row).
The estimation method scores relatively lower on adjusted $R^2$ for the simplest parameter specifications, but quickly reaches parity with the OLS. 
We use adjusted $R^2$ as a metric because additional terms are penalized (Equation \ref{eqn:rsquare}, where $n$ is the number of samples and $k$ is the number of features): 
\begin{equation}
    \centering
    \label{eqn:rsquare}
        \hspace{10mm} R^{2}_{adj} = 1 - \frac{(n-1) \cdot (1 - R^{2})}{n - k}
\end{equation}
We use the implementation of the Bayesian Ridge estimator from the scikit-learn package in Python \citep{scikit-learn}. 

An additional diagnostic of fit quality is the distribution of residuals: normally or near-normally distributed residuals imply that errors around the fit are random and unbiased. 
When fitting Equation \ref{eqn:features_original} to the GGCMI Phase II dataset, the distribution of the residuals depends on the number of features included in the regression, the method for estimating the parameters, and the target distribution in the training set. The residuals are only normally distributed (pvalue > 0.05 in the Shapiroâ€“Wilk test) for a single model, PEPIC, for any specification tested here, but their skew is relatively small except in a single case, EPIC-TAMU maize (Figure \ref{fig:features}, fourth row).
While including higher-order terms in the statistical model generally reduces residual skew, for EPIC-TAMU maize it increases skew instead, but also reduces the error in cross-validation, which we consider more important in the context of emulation.
The residual distribution suggests that projections using the EPIC-TAMU maize emulator will tend to be biased high, but in practice the overall magnitude of these errors is below 2\% of yield changes. (See Section 4.2.)

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Emulator evaluation}
\label{S:4}
In this section we show illustrations of GGCMI model yield responses to climate perturbations  and evaluate the ability of our emulators to reproduce them.   
Model emulation with the parametric method used here requires that crop yield responses be sufficiently smooth and continuous to allow fitting with a relatively simple functional form; in Section \ref{S:4.1} we show that this condition largely holds in the GGCMI Phase II simulations. 
In section \ref{S:4.2} we evaluate metrics of emulator performance and show that emulation errors -- discrepancies between emulation and simulation -- are generally small, especially when compared to the differences across crop models or to projected yield changes. 
Emulation errors become problematic only in certain, limited geographic locations, usually where crops are not currently grown. 
We analyze here results using the 34-term polynomial of Equation \ref{eqn:features_original}; see Supplemental Material Section 8 for analogous analysis of the 23-term polynomial of Equation \ref{eqn:features_reduced}.
Finally, in Section \ref{S:4.3}, we assess the emulator's ability to reproduce crop yields in a more realistic future simulation driven by a climate model projection, and find that any effects of changes in climate variability not included in the GGCMI Phase II training set are generally small relative to the effects of mean changes.

\subsection{Yield response}
\label{S:4.1}
Crop yields show strong spatial differentiation across geographic regions, and emulators are able to readily reproduce these. Figure \ref{fig:map_pattern} illustrates the spatial yield pattern under current climate for one crop and model (maize in LPJmL). Absolute emulation errors are low --  99.8\% of grid cells have errors below 0.5 tons ha$^{-1}$ -- but 
emulation errors as a percentage of baseline yield can be large in areas with low potential yield and no current cultivation in the real world (e.g.\ the Sahara, Patagonia).
These regions are not currently viable for agriculture and may never become viable even under extreme climate change.  
Emulator spatial skill varies across models and crops, with maize being the quantitatively easiest to emulate across all models and locations.

\begin{figure*}[ht]
\centering
    \includegraphics[width=16.0cm]{figures/lpjml_maize.png}
    \caption{
    Illustration of spatial pattern in baseline yield successfully captured by the emulator:
    simulated (\textbf{a.}) and emulated (\textbf{b.}) yield under historical (1981-2010) conditions for rainfed maize from the LPJmL model.
    Absolute yield differences (\textbf{c.}) are less than 0.5 ton ha$^{-1}$ in almost all (99.8\%) grid cells across the globe.
    Percent difference (from simulated baseline, \textbf{d.}) is below 5\% in most (75\%) grid cells currently cultivated in the real world.
    Approximately 7\% of all grid cells, but only 3\% of currently cultivated grid cell, have emulated yields that differ from the baseline simulation by more than 20\%.
    Notable exceptions include areas with very low simulated baseline yield, including for example the Sahara, the Andes, and northern Quebec. 
    Percent error weighted by cultivation area globally is essentially zero (see also Table \ref{table:ASE}).
    Performance varies by crop and model. 
    See Supplemental Figures in Section 9 for more examples.
    }
   \label{fig:map_pattern}
\end{figure*}

\begin{figure*}[ht]
\centering
    \includegraphics[width=16.3cm]{figures/regression_example.png}
    \caption{
    Illustration of spatial variations in yield response, which are successfully captured by the emulator. 
    Panels show simulations (points) and emulations (lines) of rainfed maize in the pDSSAT model in six example locations selected to represent high-cultivation areas around the globe. 
    Legend includes hectares cultivated in each selected grid cell. 
    Each panel shows variation along a single variable, with others held at baseline values. 
    Dots show climatological mean yields and lines the results of the full 4D emulator of Equation \ref{eqn:features_original}. 
    In general the climatological response surface is sufficiently smooth that it can be represented within the sampled variable space by the simple polynomial used in this work. 
    In some cases extrapolation would produce misleading results, and the emulator fails in conditions where yield response changes abruptly. 
    Failure is illustrated here by rainfed maize in north-central Ontario for the PROMET model (in gray), which shows present-day yields of zero rising abruptly if temperature warms by 4 degrees.
    }
   \label{fig:regression}
\end{figure*}

Yield responses to the four main drivers considered here (C, T, W, and N) are also quite diverse across locations, crops, and models, but in nearly all cases the local climatological mean responses are smooth enough to permit emulation with the functional form used here.
Figure \ref{fig:regression} illustrates the geographic diversity of responses within a single crop and model, for rainfed maize in pDSSAT. 
While the CO$_2$ responses (in ton ha$^{-1}$/ppm) are quite similar, the  precipitation response is stronger in more arid locations and the nitrogen responses appear strongly location-dependent. 
The heterogeneity in response supports the choice of emulating at the grid cell level. 
In regions with current cultivation, yields evolve smoothly across the space sampled, and the polynomial fit captures the climatological-mean response to perturbations well. 
Emulators do perform poorly in a few regions that involve discontinuous or irregular yield responses. 
Poor performance is illustrated here with PROMET maize in northern Canada, which is too cold for maize at present in PROMET (0 ton ha$^{-1}$ yield), but which shows an abrupt rise to moderate yields once temperature rises by 4 degrees.
Under these conditions, the 3rd order polynomial cannot fit the response, and errors are high. See Section \ref{S:4.2} for additional discussion. 

Crop yield responses in all models generally follow similar functional forms at any given location, though with a spread in magnitude (Figure \ref{fig:regression_2}, which shows rainfed maize in northern Iowa in a selection of GGCMI models). 
Absolute yield differences between models can be substantial because some models are uncalibrated.
In general, models are most similar in their responses to temperature perturbations, and least similar to changes in CO$_2$. 
That is, CO$_2$ fertilization effects \textit{within} a single model are consistent across locations, but CO$_2$ effects differ strongly \textit{across} models. 

\begin{figure*}[h!!]
\centering
    \includegraphics[width=16.3cm]{figures/regression_example_2.png}
    \caption{
    Illustration of variations in yield response across models, again successfully captured by the emulator. 
    Panels show simulations and emulations from six representative GGCMI models for rainfed maize in the same Iowa grid cell shown in Figure \ref{fig:regression}, with the same plot conventions. 
    Three models (PROMET, JULES, and CARAIB) that do not simulate the nitrogen dimension are omitted for clarity. 
    Models are uncalibrated, producing spread in absolute yields. 
    While most model responses can readily emulated with a simple polynomial, some response surfaces diverge slightly from the polynomial form, producing emulation error (e.g.\ pDSSAT here, for water), but 
    resulting error generally remains small relative to differences across models.
    }
   \label{fig:regression_2}
\end{figure*}

Note that while the nitrogen dimension is important, it is also the most troublesome to emulate in the GGCMI Phase II experiment because of its limited sampling. 
The GGCMI Phase II protocol specified only three nitrogen levels (10, 60 and 200 kg~N y$^{-1}$ ha$^{-1}$), so a third-order fit would be over-determined but a second-order fit can result in potentially unphysical results. 
Steep and nonlinear declines in yield with lower nitrogen levels mean that some regressions imply a peak in yield between the 100 and 200 kg~N y$^{-1}$ ha$^{-1}$ levels (Figure \ref{fig:regression_2}, right). 
While reduced yields under high nitrogen levels are physically possible and could reflect over-application at particular times in the growing period, they are implausible at the magnitude shown here and likely an artifact of the fit. 
The Bayesian Ridge estimator mitigates the `peak-decline effect' in the nitrogen dimension relative to ordinary least squares, but does not entirely remove it. 
The polynomial fit also cannot capture the well-documented saturation effect of nitrogen application \citep[e.g.][]{Torsten77} as accurately as would be possible with a non-parametric model. 

\subsection{Emulator performance metrics}
\label{S:4.2}
\begin{figure*}[ht]
\centering
    \includegraphics[width=16.3cm]{figures/error_grid_new.png}
    \caption{
    Assessment of emulator performance over currently cultivated areas based on normalized error (Equations \ref{eqn:error}). 
    We show performance of all 9 models emulated, over all crops and all sampled T and W inputs (``ir.'' indicates the irrigated W$_{\infty}$ setting), but with CO$_2$ and nitrogen held fixed at baseline values. 
    Large columns are crops and large rows models; squares within are T, W scenario pairs. 
    Colors denote the fraction of currently cultivated hectares (``area frac'') for each crop with normalized area $e$ less than 1 indicating the the error between the emulation and simulation less than one standard deviation of the ensemble simulation spread. 
    Of the possible 63 scenarios at a single CO$_2$ and N value, we consider only those for which all 9 (8 for rice, soybean, and winter wheat) models submitted data (Figure S1) so the model ensemble standard deviation can be calculated uniformly in each case. 
    JULES did not simulate winter wheat and LPJ-GUESS did not simulate rice and soybean. Emulator performance is generally satisfactory, with some exceptions. 
    Emulator failures (significant areas of poor performance) occur for individual crop-model combinations, with performance generally degrading for colder and wetter scenarios.
    }
   \label{fig:error_360}
\end{figure*}

\begin{figure*}[ht]
\centering
    \includegraphics[width=16.3cm]{figures/CARAIB_spatial_error.png}
    \caption{
    Illustration of our first test of emulator performance, applied to the CARAIB model for the T+4 scenario for rainfed crops. 
    Colors indicate the normalized emulator error $e$, where $e > 1$ means that emulator error exceeds the multi-model standard deviation. 
    For consistency, we show $e$ only for geographic areas simulated by at least six models and where baseline yields are greater than 0.5 ton ha$^{-1}$.
    Emulator performance is generally good relative to model spread in areas where crops are currently cultivated (compare to Figure S2-S3) and in temperate zones in general; emulation issues occur primarily in marginal areas with low yield potentials. 
    }
   \label{fig:error}
\end{figure*}

Our emulators collectively consist of nearly 3 million individual regressions, so developing concise performance metrics poses a challenge.
No general agreed-upon criteria exist for defining an acceptable crop model emulator, so we present two different metrics below, one relatively loose and one more stringent.  
Both metrics assess the ability of the emulator to reproduce simulated crop yields in the GGCMI Phase II experiment. 
In this section we show only results from emulators based on the 34-term Equation \ref{eqn:features_original};
see Supplemental Material Section 8 for analogous assessment of emulators based on the 23-term Equation \ref{eqn:features_reduced}.

\smallskip
\textit{1. Normalized error.} 
We take as our first metric what we term the ``normalized error'', which compares the fidelity of an emulator to the inter-model spread. 
For a multi-model comparison exercise like GGCMI Phase II, a reasonable though loose emulator criterion is that its errors be small relative to inter-model differences. The normalized error $e$ is defined separately for each C,T,W,N scenario $s$ as the difference between emulated and simulated fractional yield changes, normalized by the standard deviation in simulated changes across all models: 

\begin{align}
    \hspace{10mm} e_{\: s}\  = \ & \frac{F_{em, \: s}-F_{sim, \: s}}{\sigma_{sim, \: s}}
    \intertext{where $F$ is the fractional change in yields $Y$ between scenario $s$ and baseline $b$:}
    \hspace{10mm} F_{\: s} \ = \ & \frac{Y_{s}-Y_{b}}{Y_{b}}
    \label{eqn:error}
\end{align}

\noindent We calculate the mean error for each grid cell, model, and crop in each C,T,W,N scenario by comparing emulated and simulated yields. 
A normalized error $e<1$ means that any deviation of the emulation from the simulation is less than 1 standard deviation of the inter-model spread.

Evaluation of this metric implies that GGCMI Phase II emulators are generally satisfactory. 
Emulator performance is illustrated in Figure \ref{fig:error_360}, which shows all models and crops crops over currently cultivated area.
Over all crops and models, the average normalized error $e < 1$ over 95\% of currently cultivated area.
For maize, the most tractable crop to emulate, all 9 models return $e < 1$ over 97\% of currently cultivated area. 
Only three crop-model combinations are problematic, returning $e < 1$ over less than 90\% of cultivated area even when using the 34-term statistical model: PROMET and CARAIB for soybeans (79\% and 83\%), and JULES for spring wheat (85\%).
Misfits typically occur when models show strong discontinuities in yield response (as shown in Figure \ref{fig:regression}), or when carbon fertilization gains interact nonlinearly with changes in temperature or water.
Including higher-order C terms helps in the latter case but does not reduce emulator errors to zero. 
See Supplemental Figures S21-S22 for examples of worst-case emulator failures.

While Figure \ref{fig:error_360} shows only currently cultivated land, performance can be worse in locations where crops are not currently cultivated, or on marginal lands where current potential yields are low. (In general, emulator performance is poor anywhere that models show steep yield changes once some threshold has been reached, whether these are abrupt gains or complete crop failures.) 
Figure \ref{fig:error} illustrates this effect for CARAIB in the T+4 scenario, showing normalized error over all simulated area with non-zero baseline yield and at least 6 models providing simulations. CARAIB emulator performance is generally good where crops are grown but can be poor ($e > 2$) in arid or mountainous zones, e.g.\ the edges of the Sahara, Inner Mongolia, South Africa and Southern Australia. (See Supplemental Material Section 10 for analogous figures for all crop and model combinations.)
Note that the choice of statistical model for emulation involves a trade-off in the spatial pattern of errors: adding terms to the statistical model increases emulator fidelity in problematic ``fringe'' areas where crops are currently not cultivated, but reduces it slightly over high-yield areas.
For example, CARAIB maize emulators have normalized error $e < 1$ over 98.8\% of currently cultivated land with the reduced 23-term Equation \ref{eqn:features_reduced} but only 98.5\% with the 34-term Equation \ref{eqn:features_original}. 
Over simulated uncultivated land, CARAIB maize emulators have $e < 1$ for only 88.7\% of area with the reduced Equation \ref{eqn:features_reduced} but 93.7\% with the full Equation \ref{eqn:features_original}. 

Note that the normalized error assessment is relatively forgiving for several reasons. 
First, it is an in-sample validation, with the emulation evaluated against the simulations actually used to train the emulator. 
Had we used a spline interpolation, the error would necessarily be zero. 
Second, the metric scales emulator fidelity not by the magnitude of yield changes in the evaluated model but by the spread in yield changes across models. 
The normalized error $e$ for a given model then depends on the particular suite of other models considered in the intercomparison exercise.  
The rationale for the choice is to relate the fidelity of the emulation to the true uncertainty, which we take as the multi-model spread, but  
the metric then has the property that where models differ more widely, the standard for emulators becomes less stringent, and vice versa.
In GGCMI Phase II the effect is manifested in the higher normalized errors for soybeans across all models, which result not because soybean yields are difficult to emulate but because models agree more closely on yield changes for soybeans than for the other crops.

\smallskip
\textit{2. Out-of-sample validation.} 
We provide a second, more stringent test of emulator performance via a cross validation (also termed an out-of-sample validation). 
In this test the GGCMI Phase II dataset is split randomly into two parts, with 90\% of the data used to train the model and the held-out 10\% used to test the fidelity of the resulting emulator.
We calculate the root mean square error (RMSE) between emulated (predicted) and actual simulated values across the test set, repeat the process twice, and average the results of the two splits. 
As a last step, we normalize the RMSE in each grid cell by dividing by the simulated yield change.

The resulting error metric is generally low.
Table \ref{table:ASE} shows the yield-change-normalized RMSE for rainfed crops in all models over currently cultivated land, both in selected major producing regions and in the global average. (We include all simulations in CTWN space and take the average error value.) 
Mean grid cell RMSE is below 5\% of yield changes in all cases, or in absolute terms 
less than 0.2 ton ha$^{-1}$ for all except JULES soy, which is 0.36 ton ha$^{-1}$ in the global mean.
For irrigated crops, absolute emulator errors are generally lower, but since irrigated crops experience lower yield changes the fractional errors are similar. 
See Supplemental Material Section 11 for maps of cross validation RMSE for each crop and model.

\begin{table*}[ht]
    \caption{
    RMSE of emulator replication of simulated yields of rainfed crops, stated as a percentage of simulated yield change.
    Values are the mean grid cell error as a percentage of simulated yield change, over all currently cultivated grid cells weighted by cultivation area, for selected major regions (NA: North America, SA: South America). For comparison, global mean values are show in parentheses. 
    Errors are calculated using the 90-10 cross validation scheme described in text, with the model trained on 90\% of the data and validated on the held-out 10\% (repeated twice). All fits are made with the Bayesian Ridge method; 
    for context we mark with * those cases where the Bayesian Ridge is required because the OLS linear model fails (e.g.\ PEPIC, which has the lowest number of samples at n=121).
    } 
    \label{table:ASE}
    \begin{tabular}{l | c | c | c | c | c} 
        \hline
        \textbf{Model} & \textbf{NA Maize \%} & \textbf{SA Soybean \%} & \textbf{SE Asian Rice \%} & \textbf{NA S. Wheat \%} & \textbf{European W. Wheat \%} \\ \hline
        \textbf{CARAIB}    & 0.7 (0.9)  & 2.4 (2.4)  & 2.4 (2.4)  & 1.3 (1.4)  & 2.7 (1.9)  \\ \hline
        \textbf{EPIC-TAMU} & 2.4 (1.8)  & 1.8 (2.6)  & 1.6 (1.6)  & 1.8 (1.9)* & 1.1 (1.1)  \\ \hline
        \textbf{JULES}     & 2.6 (2.6)  & 4.6 (4.0)  & 1.6 (1.7)  & 2.0 (2.2)  & NA         \\ \hline
        \textbf{GEPIC}     & 2.1 (2.4)  & 1.0 (1.2)  & 2.0 (2.1)  & 3.7 (3.3)  & 4.0 (2.9)  \\ \hline
        \textbf{LPJ-GUESS} & 1.0 (1.1)  & NA         & NA         & 1.0 (1.3)  & 1.0 (1.2)  \\ \hline
        \textbf{LPJmL}     & 1.8 (1.8)  & 1.1 (1.3)  & 1.2 (1.1)  & 0.8 (1.1)  & 1.5 (1.3)  \\ \hline
        \textbf{pDSSAT}    & 1.9 (1.7)  & 1.2 (1.1)  & 1.7 (1.6)  & 1.1 (1.3)  & 1.4 (1.5)  \\ \hline
        \textbf{PROMET}    & 3.4 (2.7)* & 2.0 (2.7)* & 2.1 (1.8)* & 4.3 (3.7)* & 4.6 (3.4)* \\ \hline
        \textbf{PEPIC}     & 1.8 (1.8)* & 1.4 (1.9)* & 1.4 (1.4)* & 2.3 (2.3)* & 4.9 (2.9)* \\ \hline
    \end{tabular}
\end{table*}

Note that this metric is relatively simple and may be over-conservative.
The randomized sampling protocol for dividing training and test sets can mean that a training set omits edge simulations at the highest or lowest value in CTWN space. 
The test prediction then involves extrapolating out of the training set range (e.g.\ predicting a T+6 case when the training set extends only to T+4), an improper use of an emulator. 
Values would be lower under a different sampling strategy (e.g.\ ``leave-one-out''). 
For additional discussion of more detailed potential evaluation metrics, see e.g.\ \citet{Castruccio14}.

\smallskip
\label{S:4.3}
\subsection{Emulation of realistic climate projections}
Finally, we test the ability of an emulator based on the GGCMI Phase II perturbed mean training set to reproduce the response of a crop model driven by a realistic evolving climate scenario. The goal is to assess whether effects of future changes in temperature and precipitation distributions  are strong enough to compromise an emulator based on the GGCMI Phase II dataset.
We first drive the LPJmL crop model (representative of GGCMI  models) with climate model output under the high-end RCP 8.5 scenario.
We choose for this purpose a  climate model (HadGEM2-ES) with relatively large changes in growing-season temperature variability (Supplemental Figure S4) among members of the Coupled Model Intercomparison Project Phase 5 (CMIP-5) archive \citep{Jones2011h, Martin2011}. 
We then drive the LPJmL emulator with the HadGEM2-ES yearly-growing season anomalies, and evaluate how well the resulting emulated yields reproduce those simulated under the full climate scenario. 
The comparison suggests that globally, the results of future distributional shifts on climatological yields are small relative to the effects of mean changes (Figure \ref{fig:lpjmlrcp}). 
In the LPJmL example of Figure \ref{fig:lpjmlrcp}, emulated and simulated global production in the last decade of the simulation are identical to within 1.5\% for all crops.
Emulators also reproduce decadal variations in yields, which are especially strong in spring wheat grown in northern latitudes, and even capture much of the residual year-over-year yield variability. (R$^2$ of emulated vs.\ simulated annual yield anomalies relative to the 10-year running mean is 0.8 for spring wheat and $\sim$0.3 for all other crops.)
%The emulator also reproduces decadal variation in yields, which is especially strong in spring wheat that is grown in northern latitudes, and even captures much of the residual year-over-year yield variability. (R$^2$ of emulated vs.\ simulated annual yield anomalies relative to the 10-year running mean is 0.8 for spring wheat and $\sim$0.3 for all other crops.)

\begin{figure*}[ht]
  \centering
  \includegraphics[width = 16.3cm]{figures/LPJMLRCP85comp.png}
  \caption{
  Test of emulator performance in reproducing yield simulations made with a realistic climate projection. 
  Panels show simulated (black) and emulated (red) global production for four crops from the LPJmL model, driven with temperature and precipitation outputs from the HadGEM2-ES climate model for the RCP8.5 scenario. 
  In both cases nitrogen and CO$_2$ are held fixed, at 200 kg ha$^{-1}$ and 360 ppm.
  Points show yearly global production change from the 1981-2010 baseline, and lines show a 10-year running mean. 
  See text for discussion of relating the HadGEM2-ES temperature timeseries to the appropriate offset used in emulation.
  Emulators trained on uniform climatological offsets reproduce well the simulated production response under a realistic climate scenario: yields at end of century match to within 1.5\%. 
  }
  \label{fig:lpjmlrcp}
\end{figure*}

Distributional effects might be expected to be stronger at high latitudes, because temperature and precipitation variability are larger there, so that changes in variability can be correspondingly more important. 
However, most crops (spring wheat, winter wheat, and maize) show no emulator bias that grows with latitude.
Rice is the exception: the climatological-mean emulator slightly overpredicts yield losses in the tropics and underpredicts losses at higher latitudes (where little rice is currently grown). Poleward of 30 degrees latitude, the LPJmL simulation under the HadGEM2 RCP scenario shows a 49\% reduction in rice yields by end-of-century (without growing-season adaptation), but the GGCMI-based emulator produces a reduction of only 39\% (Supplemental Figure S10). These losses are concentrated in the lower mid-latitudes: only 20\% of global rice is cultivated poleward of 30 degrees, and only 1\% poleward of 45 degrees.
%i.e.\ emulated 10\% low bias in emulated end-of-century rice yields 

It is worth noting two complications involved in comparing emulated to simulated yields under a realistic climate change scenario, as in Figure \ref{fig:lpjmlrcp}.
First, it is not trivial to choose how to relate temperature or precipitation in the evolving climate scenario to the $T$ and $P$ offsets used as regressors to the emulator. 
Using growing-season mean temperature can lead to complications if crop models assume that growing season lengths shift under climate change. 
For consistency, we match the temperature changes in the climate scenario to their equivalent emulator regressors by calculating means over the fixed baseline growing season. 
This choice ensures that the emulation is appropriately matched to the simulation.
Second, while the emulator outputs an estimated yield change, the baseline from which that yield change is calculated will be different between simulation and emulation, because the historical climate timeseries are not identical. For example, the baseline (1981-2010) yield of winter wheat simulated by LPJmL using the AgMERRA timeseries as part of GGCMI Phase II is 7\% lower than that simulated using the HadGEM2-ES timeseries. 
To minimize the effects of different historical climate assumptions, we drive the emulator with the anomaly of the climate scenario from its own 1981-2010 mean. 
Bias in the historical climate timeseries could in theory produce discrepancies between emulated and simulated yield changes because of the nonlinearities discussed in Section 2.2, but the effect appears to play little role in the LPJmL comparison of Figure \ref{fig:lpjmlrcp}. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Emulator results and products}
\label{S:5}


\begin{figure*}[h!]
  \centering
  \includegraphics[width = 16.3cm]{figures/em_CTWN_all_crops.png}
  \caption{
  Emulated global damage functions for the five GCCMI Phase II crops over the four CTWN dimensions varied. %: CO$_2$, temperature, water, and nitrogen.
  Black line shows the multi-model mean and shaded area and colored lines the individual models. 
  Each panel shows response to one covariate for rainfed crops, with all others held constant at baseline values (e.g.\ C = 360 ppm, N = 200 kg ha$^{-1}$). 
  Damages are reported as percent change in global production over currently cultivated land relative to the 1981-2010 baseline. Note that y-axis ranges are not uniform.
  As expected, the N response is smallest in soybeans, which are nitrogen fixers, and the C response smallest in maize, which is a C4 crop. %Spring wheat has the largest inter-model spread and soybeans the smallest. 
  For an analogous figure identifying each crop model, see Supplemental Figure S11.
  }
  \label{fig:all_dims}
\end{figure*}

The crop model emulators developed here can be used for a variety of applications, because the emulator transforms the discrete simulation samples into a continuous response surface at any geographic scale. One use is construction of continuous agricultural damage functions in a flexible format. 
As an example, we present in  Figure \ref{fig:all_dims} global damage functions over each of the four dimensions tested in this study, constructed from the 4D emulation of each crop model. %  the ensemble median is shown as a bold line.

These damage functions are useful in diagnosing commonalities and differences in the responses of crop models. 
%In general, across model spread is qualitatively similar across different crops and different dimensions with some notable exceptions. 
%Figure \ref{fig:all_dims} allows drawing some immediate insights about potential crop responses to changes and the level of model agreement on those responses. %Maize has a muted response to CO$_2$ as a C4 plant, and the impacts of temperature are most consistent for soybeans .
In most cases, models agree on the sign of responses to individual factors, but the spread in model responses is comparable to the median response. Inter-model spreads are largest for spring wheat and smallest for soybeans, as also shown in Figure \ref{fig:error_360}.
Model responses to individual factors conform to expectations. As expected, the CO$_2$ response is smallest for maize, which is a C4 grass, and the nitrogen response is smallest for soybeans, which are efficient fixers of atmospheric nitrogen. Nitrogen responses in crops other than soybeans are relatively similar, and most models show saturation beginning at values less than 200 kg ha$^{-1}$.
 In nearly all crop models and for all crops except spring wheat, damages from reduced precipitation exceed benefits from increased precipitation. Spring wheat is the exception, likely because it is grown in high latitudes where rainfall may be limiting. Rice, by contrast, which is generally grown in locations with abundant water, shows nearly no benefit from increased precipitation.
Note that these damage functions do not consider whether increased precipitation might permit cultivation in new areas, and also that crop models generally do represent damages from excess soil moisture well \citep{Li2019}.

The GGCMI Phase II emulators are also intended as a tool for impacts assessments.
The T and P functions presented in Figure \ref{fig:all_dims} are not true global projections, because they emulate the conseqeunces of uniform shifts across the globe. %\citep[e.g][]{Sippel2015}. 
However, the emulator allows building analogous damage functions based on climate model output, which has more realistic spatial patterns of changes in temperature and precipitation. 
In Figure \ref{fig:globe_em}, we show emulated maize responses for 3 crop models under the RCP8.5 scenario, using output from 5 climate models from the CMIP-5 archive \citep{Taylor2012}. Losses are shown as a function of mean growing-season temperature over currently cultivated land. While these damages functions aggregate over all currently cultivated land, the global coverage of GGCMI Phase II allows impacts modelers to develop damage functions for any desired geopolitical or geographic region larger than 0.5 degrees in latitude and longitude. 


\begin{figure*}[ht]
    \centering
    \includegraphics[width = 16.3cm]{figures/global_em_maize.png}
    \caption{
    Illustration of the factors affecting yields in more realistic climate scenarios, for three different crop models. 
	Figure shows emulated yield changes (relative to 1981-2010) for maize (both rainfed and irrigated) on currently cultivated land under RCP8.5 climate projections from 5 representative CMIP-5 climate models, using changes to T only (\textbf{a}), to T and W (\textbf{b}), and to T, W, and C (\textbf{c}).  X-axis is the mean growing-season temperature change over cultivated land, computed using the historical growing season; note these values will be higher than the corresponding global mean temperature change.
    Circles are emulated yearly global production changes to 2100 (90 years $\times$ 5 climate timeseries = 450 per crop model), with x-axis the mean historical growing-season T shift over all grid cells where maize is grown (unweighted by within-cell cultivated area).
    \textbf{a:} Using only temperature changes allows comparing regional simulated and emulated values. Open squares are simulated values for each T level, with CWN at baseline; bold lines are emulated values over uniform T shifts (repeated in each panel). Emulation uncertainty (compare squares to lines) is small relative to differences across climate and crop models, and 
    mean yield changes are similar whether T changes are applied as a uniform shift or in a more realistic spatial pattern (compare lines to circles). 
    \textbf{b:} Adding in precipitation changes increases yield spread across climate projections and depresses yield slightly. 
    \textbf{c:}  CO$_2$ fertilization is small in pDSSAT, moderate in LPJmL, and very large in PROMET. 
    The separation of groups of points in PROMET (gold) results because CMIP-5 climate sensitivities differ by nearly a factor of two; points at far right are under HadGEM2-ES and MIROC.
    In RCP8.5, the 30-year-average CO$_2$ at end of century is 807 ppm \citep{riahi2011rcp}. 
	For comparison, open squares in \textbf{c} show GGCMI-II simulated production changes at T+6, W=0, C=810 ppm. (Note that  in these climate projections, mean CO$_2$ levels when T $>$ 5.8 degrees is 912 ppm.)
	See Supplemental Figures S13--14 for analogous figures for other crops (spring wheat and soybeans).
    }
    \label{fig:globe_em}
\end{figure*}

%The emulator can also be used for investigating the contributions of the different major climate drivers to production outcomes as it can project many different climate scenarios or models quickly.


% POINT 1 can split out factors to determine effects of main drivers
% for some models, T is main factor that matters (pDSSAT), but for others (PROMET) CO2 effect is even larger 
% for spring wheat (Figure 13)
% squares in right panel being aligned mean there are limited interactions between C and W terms, LPJmL shows more. Bigger effect even in Spring wheat (Figure S13).
% spatial pattern of warming doesn't affect maize much but it can matter for soybeans (Figure S14)
% CO2 effect increases spread - T to W relationship is more similar than T to C relationship? but W change doesn't make a big different 
The emulated responses of Figure \ref{fig:globe_em} allow diagnosing the factors of greatest importance to projected yield changes under future climate change. In the maize example here, temperature is the overwhelmingly dominant factor for pDSSAT, but CO$_2$ responses are far larger in PROMET. (CO$_2$ is important across models for spring wheat, see Figure S13.) For all crop models, the aggregated effects of precipitation changes are negative, exacerbating yield losses (compare T and T+W cases), because precipitation in HadGEM2 actually declines over maize cultivation regions, especially in Central and S.\ America. Precipitation effects are relatively small, however, as manifested in two ways: as only a small mean shift in yield projections for individual crop models (compare T and T+W cases), and as a relatively small increase in the spread of points here at a given temperature, despite the fact that the climate projections used involve different relationships between temperature and precipitation change.  By contrast, the carbon fertilization response for PROMET is so large that projections from climate models of different sensitivities ($\Delta$T/$\Delta$CO$_2$) become clearly separated in Figure \ref{fig:globe_em}. PROMET yield responses would be more similar if plotted as a function of CO$_2$ than they are when plotted as in Figure \ref{fig:globe_em} as a function of temperature change. 
%the distinctions becomes clear between yields calculated with . % Figure \ref{fig:globe_em} also demonstrates the importance of a C-W interaction term for LPJmL maize yields: while adding W changes reduces yields, and adding C changes increases them, the joint effect of W+C changes is more positive than that of C alone (compare open squares to circles in T+W+C case). %This interaction effect likely reflects the fact that the CO$_2$ fertilization effect is more important in cases where water is limiting.   

%Precipitation changes introduce some noise because different climate models have different P response for a given temperature change. 
%PROMET shows a near uniform reduction in yields with precipitation effects included.
%Including the direct effects of elevated CO$_2$ introduces the largest inter-model uncertainty with different crop models showing very different responses. 
%The difference in model response to CO$_2$ is much larger than differences resulting from different climate model sensitivity to CO$_2$ (T(CO$_2$)).
%Individual climate model sensitives can be seen in the separation in the PROMET response to CO$_2$.

%Emulation based on GGCMI climatological mean shifts is useful for realistic scenarios and emulator errors are small compared to climate model differences and tiny compared to crop model differences.
% POINT 2 errors of emulation are much smaller than differences across crop models or even across different climate simulations
%The differences between the emulation and the simulations for a uniform T shift are small compared to the differences across different crop models.
Disaggregating the factors driving crop yield changes also highlights the fact that errors of emulation are much smaller than the spread across crop models or even across different climate simulations.
PROMET is the most quantitatively difficult model to emulate for maize, but its  %is shown in Figure \ref{fig:globe_em} to illustrate that emulation error at the global production scale is still small compared to the spread across crop models or the spread across climate projections when all factors are included.
comparatively large emulation error (compare open squares to lines in T case) is still smaller than the spread simply due to different T patterns across climate simulations (Figure \ref{fig:globe_em}, left, compare differences between open squares and line with the spread in circles for a given temperature value). Uncertaintes in the yield damage function due to projected patterns of temperature change are in turn smaller than spread due to differing model relationships of W and T changes (Figure \ref{fig:globe_em}, middle), and for PROMET are enormously outweighed by uncertainty in climate sensitivity (Figure \ref{fig:globe_em}, right). %  the even less relative to the spread due to differences in W or C. %; these show emulated and simulated values under uniform temperature shifts.
While emulator fidelity is important to ensure, it is important to recognize that these other  uncertainties will dominate any impacts assessment exercise.
Note that the pattern-related yield effects are actually relatively small for maize. (In Figure \ref{fig:globe_em}, left, compare lines, which show yield changes under uniform temperature shifts, to circles,  which show changes under realistic warming scenarios). Pattern-related yield effects can be larger for other crops, and the uncertainties due to climate projections correspondingly larger: see for example soybeans in Supplemental Figure S14. 
%for maize, whose production is relatively restricted in latitude (56\% of global production in LPJmL is between 30--50 degrees absolute latitude)

%The pattern oYield changes under the uniform temperature shift over growing area is not very different from realistic scenarios (though it biases LPJmL low). 
%That is, projected temperature change distribution in space do not matter that much over currently cultivated area, but are likely important to production in high latitude regions which will warm much faster than lower latitudes.


%Finally, the emulator constructed from the GGCMI perturbed mean training set reliably reproduces a realistic RCP scenario indicating that the temperature distribution in a location within the growing season is relatively insignificant when compared to the mean change.
%First, the spatial pattern of temperature change under a realistic climate scenario is relatively insignificant at the global mean production level.
%Second, the spread across climate model response increases considerably with precipitation changes and CO$_2$ effects included, with precipitation changes reducing production and CO$_2$ increasing it.
%The CO$_2$ response is more heterogeneous across crop models that precipitation changes for maize. 
%The globally gridded nature of the emulator allows for easy analysis at almost any spatial scale.
%Note that no direct comparison to the simulations is possible in cases b or c.
%Finally, the emulator can be used to quickly project crop yield responses to climate change under a variety of conditions. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% largest ever crop modeling exercise - over 50% of calories, allows global-scale emulation
% recap that it's useful even in realistic scenarios.
% Alexander
\section{Discussion and conclusions} 
\label{S:6}
In this work we describe a new class of global gridded crop model emulators for 5 crops (maize, soy, rice and spring and winter wheat) and 9 process-based crop models, based on the  GGCMI Phase II dataset.
The systematic parameter sampling of the GGCMI Phase II experiment allows emulating climatological-mean crop yield responses with a relatively simple statistical model and isolating long-term impacts from confounding factors that lead to different year-over-year responses. Across all models, emulation errors over currently cultivated land never exceed 5\% of yield changes at either global or regional scale. 
The systematic sampling provides information on the influence of multiple interacting factors in a way that realistic climate model simulations cannot, and the use of a parametric statistical model allows physical interpretation of parameter values. While emulators based on the GGCMI Phase II protocol of uniform perturbations to historical climate will not reproduce any effects of changing variability in futre climate projections (any temperature variability changes or precipitation variability changes other than multiplicative mean shifts), in practice these effects appear to be small, at least on the regionally aggregated level. 
% XX maybe leave this out as too long... In an exercise with the LPJmL model run over a realistic climate scenario, simulated and emulated crop yields match to within 1.5\%.  These results suggest that emulation based on a structured uniform-perturbation experiment can provide a powerful tool for diagnosing factors driving future crop yield changes in process-based crop models. %Emulators provide a lightweight, flexible tool for both model diagnosis and impacts assessments.

%, we show that emulation based on uniform climate shifts is able to sufficiently reproduce the response of a crop model driven by a more realistic climate scenario at the global scale, with some relatively minor errors for rice at high latitudes.
%Excellent agreement between emulation and simulation at the temporally aggregate timescale shows the value of the emulator as an impacts assessment tool.

%providing a lightweight, flexible tool The use of a parametric statistical model in turn offers the possibility of physical interpretation of parameter values that can assist in model intercomparison and evaluation. 
%We show that the polynomial emulation of the mean-climatological response is feasible, with out of sample prediction errors less than 5\% of yield changes both regionally and at the global scale.

Emulators provide powerful tools for both model comparison and impacts assessments by capturing the responses of process-based crop models in a lightweight form. The emulators provide over three orders of magnitude reduction in data storage: the yield output for a single crop model that simulates all GGCMIP Phase II scenarios for 5 crops is $\sim$12.5 GB; equivalent global gridded emulator parameters are only $\sim$20 MB and allow emulation of arbitrary future scenarios. Computational requirements are nearly negligible: a thousand years of global 0.5 degree yields, i.e\ $\sim$40,000 individual yield projections, can be emulated in 20 seconds on a laptop computer. 
The emulators can be used to develop standalone damage functions at any geographic scale larger that 0.5 degrees, or can be integrated directly into a larger integrated assessment model (IAM) framework. 

Several cautions should be noted when using the emulators presented here. 
First, extrapolation outside the GGCMI Phase II sample space should be avoided; we have not formally tested the utility of these functional forms in extrapolating beyond a training set. % extrapolation is unwise in general, and we have not formally tested the utility of these functional forms in predictions made outside the range of a training set. 
%Emulators by design reduce the complexity of process-based simulations and can thus deviate from the raw simulation output. 
%Deviations from the simulation are especially prominent in models with limited sampling or in geographic regions outside the current cultivated area.
Second, while the emulators are valuable for understanding the shape of yield responses and the factors that drive them, the absolute values of emulated yields should be treated with caution. Because the GGCMI Phase II simulation protocol was designed to focus on changes in yield and not on replicating real-world yields, most models are not formally calibrated, and their
emulators should be used for absolute impacts projections only in combination with historical yield data. 
%Becasue such changes are uncertain and remain poorly characterized in climate models and crop models %\citep[e.g.][]{Alexande2006, Kodra2014}

%Follow-up experiments may wish to focus of the impacts of variability changes by testing crop models on specified variability changes in temperature and precipitation in a fashion similar to GGCMI phase II. 
%Several recent studies have described procedures for generating simulations that combine historical data with model projections of changes in the marginal distributions or temporal dependence of temperature and precipitation \citep[e.g.][]{Leeds2015, poppick2016, Won16, Haugen2018}.

The GGCMI Phase II dataset and emulators invite a broad range of potential future avenues of analysis. %, especially because emulation allows distillation of the large dataset into a tractable form. 
Potential future studies could include a detailed examination of interaction terms, robust quantification of model sensitivities to input drivers, exploration of yield responses to extremes or interannual variability, and evaluation of geographic shifts in optimal growing regions. 
Studies of yield responses to changes in growing-season variability would require new simulations, but the GGCMI Phase II emulators provide a ready means of testing the null hypothesis that such effects are small. Similar structured training sets could be constructed to directly study responses to variability changes: see e.g.\ \citet{poppick2016, Haugen2018} for methods of constructing synthetic climate timeseries with altered variability. 
The GGCMI Phase II dataset also enables studies of emulation itself, including more systematic evaluation of statistical model specifications or machine learning methods. 
In general, the GGCMI Phase II experiment demonstrates the promise and utility of systematic parameters sweeps for improving understanding of the factors driving crop responses and for evaluating and improving process-based crop models.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\codedataavailability{The polynomial emulator parameter matrices for all crop model emulators are available at {doi.org/XXXXX}}

%\appendix
%\section{}
%\subsection{Data Access}
%\noappendix %% use this to mark the end of the appendix section

\authorcontribution{J.E., C.M, A.R., J.F., and E.M.\ designed the research. C.M., J.J., P.F., C.F., L.F., R.C.I., I.J., C.J., W.L., S.O., M.P., T.P., A.Re., K.W., and F.Z.\ performed the simulations. J.F., J.J., A.S., M.L., Z.W., and E.M.\ performed the analysis and J.F., C.M., and E.M.\ prepared the manuscript.}

\competinginterests{The authors declare no competing interests.}

\begin{acknowledgements}
We thank Michael Stein and Kevin Schwarzwald, who provided helpful suggestions that contributed to this work. 
This research was performed as part of the Center for Robust Decision-making on Climate and Energy Policy (RDCEP) at the University of Chicago, and was supported through a variety of sources. 
RDCEP is funded by NSF grant \#SES-1463644 through the Decision Making Under Uncertainty program. 
J.F.\ was supported by the NSF NRT program, grant \#DGE-1735359 and by an NSF Graduate Research Fellowship, grant \#DGE-1746045. 
C.M.\ was supported by the MACMIT project (01LN1317A) funded through the German Federal Ministry of Education and Research (BMBF). 
C.F.\ was supported by the European Research Council Synergy grant \#ERC-2013-SynG-610028 Imbalance-P. 
P.F.\ and K.W.\ were supported  by the Newton Fund through the Met Office Climate Science for Service Partnership Brazil (CSSP Brazil). 
K.W.\ was supported by the IMPREX research project supported by the European Commission under the Horizon 2020 Framework programme, grant \#641811. 
A.S.\ was supported by the Office of Science of the U.S.\ Department of Energy as part of the Multi-sector Dynamics Research Program Area. 
S.O.\ acknowledges support from the Swedish strong research areas BECC and MERGE together with support from LUCCI (Lund University Centre for studies of Carbon Cycle and Climate Interactions). 
R.C.I.\ acknowledges support from the Texas Agrilife Research and Extension, Texas A \& M University. 
This is paper number 35 of the Birmingham Institute of Forest Research. 
Computing resources were provided by the University of Chicago Research Computing Center (RCC).
\smallskip
\textit{This material is based upon work supported by the National Science Foundation Graduate Research Fellowship Program under Grant No. (DGE-1746045). 
Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the National Science Foundation.}
\end{acknowledgements}

\bibliographystyle{copernicus}
\bibliography{bib}

\end{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%The ability of our emulator to capture ... suggests that the temperature distribution in a location within the growing season is relatively insignificant when compared to the mean change on longer timescales. 
%The year-to-year emulation does not match the yearly simulated values (Figure \ref{fig:lpjmlrcp}, points) as well as the climatological mean (Figure \ref{fig:lpjmlrcp}, lines), indicating the importance of the growing season temperature distribution at the yearly time scale. 
%We do not intend the emulator to be used to project yearly yields.
%First, the growing season used for calculating the temperature and precipitation changes in the climate model run in especially important here because growing seasons vary dynamically in models based on temperature. 
%In the case shown here, using the growing seasons from the baseline GGCMI Phase II simulations provides the best result because the emulator implicitly includes the crop model response to changing growing season. 
%If the growing season from the RCP crop model is utilized (an unrealistic use-case because these simulations do not exist for every possible emulator application) you are likely to over- or under-estimate the growing season temperature or precipitation changes depending on the seasonality of weather in the growing sseason.


\begin{table*}[hb]
    \caption{
    Root mean squared error of the emulator representation of a simulation as a percentage of simulated yield change for the cross-validation process, for rainfed crops. Values are the mean grid cell error as a percentage of baseline yield, over all currently cultivated grid cells weighted by cultivation area. 
    Errors are calculated using the 90-10 cross validation scheme described in text, where the model is trained on 90\% of the data and validated on the held-out 10\% (repeated twice). 
    Values with * are cases where the OLS linear model fails. PEPIC has the lowest number of samples (n=121), so cannot be fit with the OLS and requires the Bayesian Ridge method.
    } 
    \label{table:ASE}
    \begin{tabular}{l | c | c | c | c | c} 
        \hline
        \textbf{Model}     & \textbf{N.A. Maize (\%)} & \textbf{S.A. Soybean (\%)} & \textbf{Rice (\%)} & \textbf{S. Wheat (\%)} & \textbf{W. Wheat (\%)} \\ \hline
        \textbf{CARAIB}    & 0.91 & 2.38 & 2.42 & 1.40  & 1.87    \\ \hline
        \textbf{EPIC-TAMU} & 1.76 & 2.55 & 1.60 & 1.94* & 1.12    \\ \hline
        \textbf{JULES}     & 2.64 & 4.02 & 1.70 & 2.15 & NA       \\ \hline
        \textbf{GEPIC}     & 2.40 & 1.25 & 2.13 & 3.29 & 2.89     \\ \hline
        \textbf{LPJ-GUESS} & 1.09 & NA   & NA   & 1.30 & 1.21     \\ \hline
        \textbf{LPJmL}     & 1.81 & 1.32 & 1.08 & 1.05 & 1.28     \\ \hline
        \textbf{pDSSAT}    & 1.72 & 1.13 & 1.57 & 1.27 & 1.51     \\ \hline
        \textbf{PROMET}    & 2.69* & 2.70* & 1.84* & 3.74* & 3.36* \\ \hline
        \textbf{PEPIC}     & 1.79* & 1.87* & 1.39 & 2.29* & 2.87* \\ \hline
    \end{tabular}
\end{table*}
